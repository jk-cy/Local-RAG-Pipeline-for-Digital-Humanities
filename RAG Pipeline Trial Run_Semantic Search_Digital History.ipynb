{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59974905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennykwok/Library/Mobile Documents/com~apple~CloudDocs/Documents/Coding Notebook/RAG/Jenny's pipeline/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jennykwok/Library/Mobile Documents/com~apple~CloudDocs/Documents/Coding Notebook/RAG/Jenny pipeline/(2010) Kirschenbaum - What is Digital Humanities.pdf\n"
     ]
    }
   ],
   "source": [
    "# import PDF\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# your pdf path\n",
    "pdf_path = \"/sample_data/(2010) Kirschenbaum - What is Digital Humanities.pdf\"\n",
    "print(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/jennykwok/Library/Mobile Documents/com~apple~CloudDocs/Documents/Coding Notebook/RAG/Jenny pipeline/(2010) Kirschenbaum - What is Digital Humanities.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "# Download PDF onine if not availale locally\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"[INFO] File doesn't exist, downloading...\")\n",
    "\n",
    "    # Enter URL of PDF\n",
    "    url = \"https://mkirschenbaum.wordpress.com/wp-content/uploads/2011/03/ade-final.pdf\"\n",
    "\n",
    "    # the local filename to save the download file\n",
    "    filename = pdf_path\n",
    "\n",
    "    # send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # check if the request was successful\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # open the file and save it\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO] The file has been downloaded and saved as {filename}\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"[INFO] Failed to download the file. Status code: {response.status_code}\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ccb888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMuPDF is installed and the fitz module is available.\n"
     ]
    }
   ],
   "source": [
    "# Open the PDF file, see: http://github.com/pymupdf/PyMuPDF\n",
    "import fitz\n",
    "\n",
    "print(\"PyMuPDF is installed and the fitz module is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec93dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jennykwok/Library/Mobile Documents/com~apple~CloudDocs/Documents/Coding Notebook/RAG/Jenny's pipeline/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "7it [00:00, 46.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -5,\n",
       "  'page_char_count': 3679,\n",
       "  'page_word_count': 599,\n",
       "  'page_sentence_count_raw': 22,\n",
       "  'page_token_count': 919.75,\n",
       "  'text': 'ADE Bulletin ◆ Number 150, 2010 55 The author is associate  professor of English and  associate director of the  Maryland Institute for  Technology in the Hu\\xad manities at the University  of Maryland. A version of  this article was presented  at the 2010 ADE Sum\\xad mer Seminar East in  Adelphi, Maryland. People who say that the last battles of the computer revolution in En\\xadglish departments have been  fought and won don’t know what they’re talking about. If our current use of computers in En\\xadglish  studies is marked by any common theme at all, it is experimentation at the most basic level. As a pro\\xad fession, we are just learning how to live with computers, just beginning to integrate these machines  effectively into writing- and reading-\\xadintensive courses, just starting to consider the implications of the  multilayered literacy associated with computers. \\x08 —Cynthia Selfe What is (or are) the “digital humanities,” aka “humanities computing”? It’s tempt\\xad ing to say that whoever asks the question has not gone looking very hard for an  answer. “What is digital humanities?” essays like this one are already genre pieces.  Willard McCarty has been contributing papers on the subject for years (a mono\\xad graph too). Under the earlier appellation, John Unsworth has advised us “what is  humanities computing and what is not.” Most recently Patrik Svensson has been  publishing a series of well-\\xaddocumented articles on multiple aspects of the topic,  including the lexical shift from humanities computing to digital humanities. More\\xad over, as Cynthia Selfe in an ADE Bulletin from 1988 reminds us, computers have  been part of our disciplinary lives for well over two decades now. During this time  digital humanities has accumulated a robust professional apparatus that is probably  more rooted in En\\xadglish than any other departmental home. The contours of this professional apparatus are easily discoverable. An organiza\\xad tion called the Alliance of Digital Humanities Organizations hosts a well-\\xadattended  annual international conference called Digital Humanities (it grew out of an earlier  annual series of conferences, hosted jointly by the Association for Computers and the  Humanities and the Association for Literary and Linguistic Computing since 1989).  There is Blackwell’s Companion to Digital Humanities. There is a book series (yes, a  book series), Topics in the Digital Humanities, from the University of Illinois Press.  There is a refereed journal called Digital Humanities Quarterly, one of several that  serve the field, including a newer publication, Digital Studies / Le champ numérique,  sponsored by the Canadian Society for Digital Humanities (Société pour l’Étude  des Médias Interactifs). The University of Victoria hosts the annual Digital Humani\\xad ties Summer Institute to train new scholars. Crucially, there are digital humanities  centers and institutes (probably at least one hundred worldwide, some of them estab\\xad lished for a decade or more with staffs numbering in the dozens): these are served by  an organization known as centerNet. There have been digital humanities manifestos  (I know of at least two) and FAQs, colloquia and symposia, workshops and special  sessions. Not to mention, of course, that a gloss or explanation of digital humani\\xad ties is implicit in every mission statement, every call for papers and proposals, every  What Is Digital Humanities and What’s It Doing in  English Departments? Matthew G. Kirschenbaum ADE and the Association of Departments of En\\xadglish are trademarks owned by the Modern Language Association.  © by the Association of Departments of En\\xadglish, CrossRef DOI: 10.1632/ade.150.55, ISSN 0001-0898'},\n",
       " {'page_number': -4,\n",
       "  'page_char_count': 3772,\n",
       "  'page_word_count': 614,\n",
       "  'page_sentence_count_raw': 20,\n",
       "  'page_token_count': 943.0,\n",
       "  'text': 'ADE Bulletin ◆ Number 150, 2010 56 What Is Digital  Humanities and  What’s It Doing in  En\\xadglish Departments? Matthew G.  Kirschenbaum strategic plan and curriculum-\\xaddevelopment document, every hiring request, and so  forth that invokes the term. Or the countless times the question has been visited on  electronic discussion lists, blogs, Facebook walls, and Twitter feeds, contributing all  the flames and exhortations, celebrations and screeds one could wish to read. We could also, of course, simply Google the question. Google takes us to Wikipe\\xad dia, and what we find there is not bad: The digital humanities, also known as humanities computing, is a field of study,  research, teaching, and invention concerned with the intersection of computing and  the disciplines of the humanities. It is methodological by nature and interdisciplinary  in scope. It involves investigation, analysis, synthesis and presentation of information  in electronic form. It studies how these media affect the disciplines in which they are  used, and what these disciplines have to contribute to our knowledge of computing. As a working definition this serves as well as any I’ve seen, which is not surprising  since a glance at the page’s View History tab reveals individuals closely associated  with the digital humanities as contributors. At its core, then, digital humanities is  more akin to a common methodological outlook than an investment in any one  specific set of texts or even technologies. We could attempt to refine this “outlook”  quantitatively, using some of the very tools and techniques digital humanities has  pioneered. For example, we might use a text-\\xadanalysis tool named Voyeur developed  by Stéfan Sinclair to mine the proceedings from the annual Digital Humanities con\\xad ference and develop lists of topic frequencies or collocate key terms or visualize the  papers’ citation networks. We could also choose to explore the question qualitatively,  by examining sets of projects from self-\\xadidentified digital humanities centers. At the  University of Maryland, where I serve as an associate director at the Maryland In\\xad stitute for Technology in the Humanities, we support work from “Shakespeare to  Second Life” as we’re fond of saying: the Shakespeare Quartos Archive, funded by  a joint grant program administered by the United Kingdom’s JISC and the NEH,  makes a searchable digital facsimile of each of the thirty-\\xadtwo extant quarto copies  of Hamlet available online, while the Preserving Virtual Worlds project, supported  by the Library of Congress, has developed and tested standards and best practices  for archiving and ensuring future access to computer games, interactive fiction, and  virtual communities. Yet digital humanities is also a social undertaking. It harbors networks of people  who have been working together, sharing research, arguing, competing, and col\\xad laborating for many years. Key achievements from this community, like the Text  Encoding Initiative or the Orlando Project, were mostly finished before the current  wave of interest in digital humanities began. Nonetheless, the rapid and remark\\xad able rise of digital humanities as a term can be traced to a set of surprisingly specific  circumstances. Unsworth, who was the founding director of the Institute for Ad\\xad vanced Technology in the Humanities at the University of Virginia for a decade and  is currently dean of the Graduate School of Library and Information Science at the  University of Illinois, has this to relate: The real origin of that term [digital humanities] was in conversation with Andrew  McNeillie, the original acquiring editor for the Blackwell Companion to Digital Hu\\xad manities. We started talking with him about that book project in 2001, in April, and'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    # more text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append(\n",
    "            {\n",
    "                \"page_number\": page_number\n",
    "                - 5,  # adjust page numbers since our PDF starts on page 42\n",
    "                \"page_char_count\": len(text),\n",
    "                \"page_word_count\": len(text.split(\" \")),\n",
    "                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                \"page_token_count\": len(text)\n",
    "                / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                \"text\": text,\n",
    "            }\n",
    "        )\n",
    "    return pages_and_texts\n",
    "\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f272a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -4,\n",
       "  'page_char_count': 3772,\n",
       "  'page_word_count': 614,\n",
       "  'page_sentence_count_raw': 20,\n",
       "  'page_token_count': 943.0,\n",
       "  'text': 'ADE Bulletin ◆ Number 150, 2010 56 What Is Digital  Humanities and  What’s It Doing in  En\\xadglish Departments? Matthew G.  Kirschenbaum strategic plan and curriculum-\\xaddevelopment document, every hiring request, and so  forth that invokes the term. Or the countless times the question has been visited on  electronic discussion lists, blogs, Facebook walls, and Twitter feeds, contributing all  the flames and exhortations, celebrations and screeds one could wish to read. We could also, of course, simply Google the question. Google takes us to Wikipe\\xad dia, and what we find there is not bad: The digital humanities, also known as humanities computing, is a field of study,  research, teaching, and invention concerned with the intersection of computing and  the disciplines of the humanities. It is methodological by nature and interdisciplinary  in scope. It involves investigation, analysis, synthesis and presentation of information  in electronic form. It studies how these media affect the disciplines in which they are  used, and what these disciplines have to contribute to our knowledge of computing. As a working definition this serves as well as any I’ve seen, which is not surprising  since a glance at the page’s View History tab reveals individuals closely associated  with the digital humanities as contributors. At its core, then, digital humanities is  more akin to a common methodological outlook than an investment in any one  specific set of texts or even technologies. We could attempt to refine this “outlook”  quantitatively, using some of the very tools and techniques digital humanities has  pioneered. For example, we might use a text-\\xadanalysis tool named Voyeur developed  by Stéfan Sinclair to mine the proceedings from the annual Digital Humanities con\\xad ference and develop lists of topic frequencies or collocate key terms or visualize the  papers’ citation networks. We could also choose to explore the question qualitatively,  by examining sets of projects from self-\\xadidentified digital humanities centers. At the  University of Maryland, where I serve as an associate director at the Maryland In\\xad stitute for Technology in the Humanities, we support work from “Shakespeare to  Second Life” as we’re fond of saying: the Shakespeare Quartos Archive, funded by  a joint grant program administered by the United Kingdom’s JISC and the NEH,  makes a searchable digital facsimile of each of the thirty-\\xadtwo extant quarto copies  of Hamlet available online, while the Preserving Virtual Worlds project, supported  by the Library of Congress, has developed and tested standards and best practices  for archiving and ensuring future access to computer games, interactive fiction, and  virtual communities. Yet digital humanities is also a social undertaking. It harbors networks of people  who have been working together, sharing research, arguing, competing, and col\\xad laborating for many years. Key achievements from this community, like the Text  Encoding Initiative or the Orlando Project, were mostly finished before the current  wave of interest in digital humanities began. Nonetheless, the rapid and remark\\xad able rise of digital humanities as a term can be traced to a set of surprisingly specific  circumstances. Unsworth, who was the founding director of the Institute for Ad\\xad vanced Technology in the Humanities at the University of Virginia for a decade and  is currently dean of the Graduate School of Library and Information Science at the  University of Illinois, has this to relate: The real origin of that term [digital humanities] was in conversation with Andrew  McNeillie, the original acquiring editor for the Blackwell Companion to Digital Hu\\xad manities. We started talking with him about that book project in 2001, in April, and'},\n",
       " {'page_number': -1,\n",
       "  'page_char_count': 3887,\n",
       "  'page_word_count': 641,\n",
       "  'page_sentence_count_raw': 19,\n",
       "  'page_token_count': 971.75,\n",
       "  'text': 'ADE Bulletin ◆ Number 150, 2010 59 What Is Digital  Humanities and  What’s It Doing in  En\\xadglish Departments? Matthew G.  Kirschenbaum some very specific ramifications. Amanda French ran the numbers and concluded  that nearly half (48%) of attendees at the Digital Humanities 2009 conference were  tweeting the sessions. By contrast, only 3% of MLA convention attendees tweeted— according to French’s data, out of about 7,800 attendees at the MLA convention only  256 tweeted. Of these, the vast majority were people already associated with digital  humanities through their existing networks of followers. Jennifer Howard, again  writing for the Chronicle, noted the centrality of Twitter to the DH crowd and its im\\xad pact on scholarly communication, going so far as to include people’s Twitter identities  in her roundup of major stories from the convention. Inside Higher Ed also devoted  coverage to Twitter at the MLA convention, noting that Rosemary G. Feal was using  it to connect with individual members of the organization—not surprisingly, many  of them DHers. Feal, in fact, kept up a lively stream of tweets throughout the confer\\xad ence, gamely mixing it up with the sometimes irreverent back-channel conversation  and, in a scene out of Small World had it only been written twenty years later, issued  an impromptu invite for her “tweeps” to join the association’s elite for nightcaps in  the penthouse of one of the convention hotels. While it’s not hard to see why the academic press devoured the story, there’s more  going on than mere shenanigans. Twitter, along with blogs and other online outlets,  has inscribed the digital humanities as a network topology, that is to say, lines drawn  by aggregates of affinities, formally and functionally manifest in who follows whom,  who friends whom, who tweets whom, and who links to what. Digital humanities  has also, I would propose, lately been galvanized by a group of younger (or not so  young) graduate students, faculty members (both tenure line and contingent), and  other academic professionals who now wield the label “digital humanities” instru\\xad mentally amid an increasingly monstrous institutional terrain defined by declin\\xad ing public support for higher education, rising tuitions, shrinking endowments, the  proliferation of distance education and the for-\\xadprofit university, and, underlying it  all, the conversion of full-\\xadtime, tenure-\\xadtrack academic labor to a part-\\xadtime adjunct  workforce. One example is the remarkable tale of Brian Croxall, the recent Emory  PhD who went viral online for a period of several weeks during and after the MLA.  Croxall had his paper, “The Absent Presence: Today’s Faculty,” read at the con\\xad vention in absentia while he simultaneously published it on his blog after finding  himself unable to afford to travel to Philadelphia because he hadn’t landed any con\\xad vention interviews. As numerous observers pointed out, Croxall’s paper, which was  heavily blogged and tweeted and received coverage in both the Chronicle and Inside  Higher Ed, was undoubtedly and by many orders of magnitude the most widely seen  and read paper from the 2009 MLA convention. These events were subsequently dis\\xad cussed in a series of cross-\\xadpostings and conversations that spilled across Twitter and  the blogosphere for several weeks after the convention ended. Many seemed to feel  that the connection to wider academic issues was not incidental or accidental, and  that digital humanities, with a culture that values collaboration, openness, nonhier\\xad archical relations, and agility might be an instrument for real resistance or reform. So what is digital humanities and what is it doing in En\\xadglish departments? The  answer to the latter portion of the question is easier. I can think of some half a dozen  reasons why En\\xadglish departments have historically been hospitable settings for this'},\n",
       " {'page_number': 1,\n",
       "  'page_char_count': 1475,\n",
       "  'page_word_count': 232,\n",
       "  'page_sentence_count_raw': 66,\n",
       "  'page_token_count': 368.75,\n",
       "  'text': 'ADE Bulletin ◆ Number 150, 2010 61 What Is Digital  Humanities and  What’s It Doing in  En\\xadglish Departments? Matthew G.  Kirschenbaum Works Cited Bobley, Brett. “What’s in a Name: NEH and ‘Digital Humanities.’” Message to the author. 12 Apr.  2010. E‑mail. “Digital Humanities.” Wikipedia. Wikimedia, 2 Nov. 2010. Web. 2 Nov. 2010. French, Amanda. “Make ‘10’ Louder; or, The Amplification of Scholarly Communication.” \\xadAmandafrench\\u200b .net. French, 30 Dec. 2009. Web. 2 Aug. 2010. Howard, Jennifer. “The MLA Convention in Translation.” Chronicle of Higher Education. Chronicle of  Higher Educ., 31 Dec. 2009. Web. 2 Aug. 2010. McCarty, Willard. Humanities Computing. New York: Palgrave, 2005. Print. Pannapacker, William. “The MLA and the Digital Humanities.” Chronicle of Higher Education. Chron\\xad icle of Higher Educ., 28 Dec. 2009. Web. 2 Aug. 2010. Selfe, Cynthia. “Computers in En\\xadglish Departments: The Rhetoric of Technopower.” ADE Bulletin 90  (1988): 63–67. Web. 2 Aug. 2010. Svensson, Patrik. “Humanities Computing as Digital Humanities.” Digital Humanities Quarterly 3.3  (2009): n. pag. Web. 2 Aug. 2010. ———. “The Landscape of Digital Humanities.” Digital Humanities Quarterly 4.1 (2010): n. pag. Web. 2 Aug.  2010. Unsworth, John. Message to the author. 5 Apr. 2010. E‑mail. ———. “What Is Humanities Computing and What Is Not?” Graduate School of Library and Information  Sciences. Illinois Informatics Inst., U of Illinois, Urbana, 8 Nov. 2002. Web. 2 Aug. 2010.'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445fd70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>3679</td>\n",
       "      <td>599</td>\n",
       "      <td>22</td>\n",
       "      <td>919.75</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 55 The author ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4</td>\n",
       "      <td>3772</td>\n",
       "      <td>614</td>\n",
       "      <td>20</td>\n",
       "      <td>943.00</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3</td>\n",
       "      <td>3659</td>\n",
       "      <td>618</td>\n",
       "      <td>18</td>\n",
       "      <td>914.75</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 57 What Is Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2</td>\n",
       "      <td>3733</td>\n",
       "      <td>617</td>\n",
       "      <td>16</td>\n",
       "      <td>933.25</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 58 What Is Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>3887</td>\n",
       "      <td>641</td>\n",
       "      <td>19</td>\n",
       "      <td>971.75</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 59 What Is Dig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0           -5             3679              599                       22   \n",
       "1           -4             3772              614                       20   \n",
       "2           -3             3659              618                       18   \n",
       "3           -2             3733              617                       16   \n",
       "4           -1             3887              641                       19   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0            919.75  ADE Bulletin ◆ Number 150, 2010 55 The author ...  \n",
       "1            943.00  ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...  \n",
       "2            914.75  ADE Bulletin ◆ Number 150, 2010 57 What Is Dig...  \n",
       "3            933.25  ADE Bulletin ◆ Number 150, 2010 58 What Is Dig...  \n",
       "4            971.75  ADE Bulletin ◆ Number 150, 2010 59 What Is Dig...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading some stats from the text\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5041dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3436.57</td>\n",
       "      <td>565.43</td>\n",
       "      <td>25.14</td>\n",
       "      <td>859.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.16</td>\n",
       "      <td>869.01</td>\n",
       "      <td>147.71</td>\n",
       "      <td>18.17</td>\n",
       "      <td>217.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>1475.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>368.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.50</td>\n",
       "      <td>3669.00</td>\n",
       "      <td>606.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>917.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3733.00</td>\n",
       "      <td>617.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>933.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>3811.50</td>\n",
       "      <td>627.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>952.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3887.00</td>\n",
       "      <td>641.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>971.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count         7.00             7.00             7.00                     7.00   \n",
       "mean         -2.00          3436.57           565.43                    25.14   \n",
       "std           2.16           869.01           147.71                    18.17   \n",
       "min          -5.00          1475.00           232.00                    15.00   \n",
       "25%          -3.50          3669.00           606.50                    17.00   \n",
       "50%          -2.00          3733.00           617.00                    19.00   \n",
       "75%          -0.50          3811.50           627.50                    21.00   \n",
       "max           1.00          3887.00           641.00                    66.00   \n",
       "\n",
       "       page_token_count  \n",
       "count              7.00  \n",
       "mean             859.14  \n",
       "std              217.25  \n",
       "min              368.75  \n",
       "25%              917.25  \n",
       "50%              933.25  \n",
       "75%              952.88  \n",
       "max              971.75  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a78618",
   "metadata": {},
   "source": [
    "#### Note: The Importance of Token Count\n",
    "\n",
    "It’s essential to consider token count when working with embedding models or Large Language Models (LLMs), as they cannot process an infinite number of tokens. During tokenization, some information may be lost or truncated, which can impact the quality of the embeddings and the model’s understanding of the text. Carefully managing token counts is crucial, especially for applications requiring detailed analysis, such as close reading of text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb3fec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e62775ad",
   "metadata": {},
   "source": [
    "#### Further Text Processing: Splitting Pages into Sentences\n",
    "\n",
    "1. Splitting on \".\"\n",
    "2. This step can be done with spaCy or nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00330916-e27f-4d7e-9bb4-6e3ddb5001ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jennykwok/Library/Mobile Documents/com~apple~CloudDocs/Documents/Coding Notebook/RAG/Jenny's pipeline/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25fd842",
   "metadata": {},
   "source": [
    "Depending on your corpus, you may choose which spaCy model to use:\n",
    "\n",
    "**Small model**\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "**Medium model**\n",
    "python -m spacy download en_core_web_md\n",
    "\n",
    "**Large model**\n",
    "python -m spacy download en_core_web_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd85201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence.,\n",
       " This is another sentence.,\n",
       " This is about digital humanities.]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, c.f. https://spacy.io/api/sentencizer\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create document instance as an example\n",
    "doc = nlp(\n",
    "    \"This is a sentence. This is another sentence. This is about digital humanities.\"\n",
    ")\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "# Print out sentences split\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04b66bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': -4,\n",
       " 'page_char_count': 3772,\n",
       " 'page_word_count': 614,\n",
       " 'page_sentence_count_raw': 20,\n",
       " 'page_token_count': 943.0,\n",
       " 'text': 'ADE Bulletin ◆ Number 150, 2010 56 What Is Digital  Humanities and  What’s It Doing in  En\\xadglish Departments? Matthew G.  Kirschenbaum strategic plan and curriculum-\\xaddevelopment document, every hiring request, and so  forth that invokes the term. Or the countless times the question has been visited on  electronic discussion lists, blogs, Facebook walls, and Twitter feeds, contributing all  the flames and exhortations, celebrations and screeds one could wish to read. We could also, of course, simply Google the question. Google takes us to Wikipe\\xad dia, and what we find there is not bad: The digital humanities, also known as humanities computing, is a field of study,  research, teaching, and invention concerned with the intersection of computing and  the disciplines of the humanities. It is methodological by nature and interdisciplinary  in scope. It involves investigation, analysis, synthesis and presentation of information  in electronic form. It studies how these media affect the disciplines in which they are  used, and what these disciplines have to contribute to our knowledge of computing. As a working definition this serves as well as any I’ve seen, which is not surprising  since a glance at the page’s View History tab reveals individuals closely associated  with the digital humanities as contributors. At its core, then, digital humanities is  more akin to a common methodological outlook than an investment in any one  specific set of texts or even technologies. We could attempt to refine this “outlook”  quantitatively, using some of the very tools and techniques digital humanities has  pioneered. For example, we might use a text-\\xadanalysis tool named Voyeur developed  by Stéfan Sinclair to mine the proceedings from the annual Digital Humanities con\\xad ference and develop lists of topic frequencies or collocate key terms or visualize the  papers’ citation networks. We could also choose to explore the question qualitatively,  by examining sets of projects from self-\\xadidentified digital humanities centers. At the  University of Maryland, where I serve as an associate director at the Maryland In\\xad stitute for Technology in the Humanities, we support work from “Shakespeare to  Second Life” as we’re fond of saying: the Shakespeare Quartos Archive, funded by  a joint grant program administered by the United Kingdom’s JISC and the NEH,  makes a searchable digital facsimile of each of the thirty-\\xadtwo extant quarto copies  of Hamlet available online, while the Preserving Virtual Worlds project, supported  by the Library of Congress, has developed and tested standards and best practices  for archiving and ensuring future access to computer games, interactive fiction, and  virtual communities. Yet digital humanities is also a social undertaking. It harbors networks of people  who have been working together, sharing research, arguing, competing, and col\\xad laborating for many years. Key achievements from this community, like the Text  Encoding Initiative or the Orlando Project, were mostly finished before the current  wave of interest in digital humanities began. Nonetheless, the rapid and remark\\xad able rise of digital humanities as a term can be traced to a set of surprisingly specific  circumstances. Unsworth, who was the founding director of the Institute for Ad\\xad vanced Technology in the Humanities at the University of Virginia for a decade and  is currently dean of the Graduate School of Library and Information Science at the  University of Illinois, has this to relate: The real origin of that term [digital humanities] was in conversation with Andrew  McNeillie, the original acquiring editor for the Blackwell Companion to Digital Hu\\xad manities. We started talking with him about that book project in 2001, in April, and'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b59b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 69.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Ensure all sentences are strings (currently spaCy datatype)\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "\n",
    "    # count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4318b8e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39msample(pages_and_texts, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558309c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3436.57</td>\n",
       "      <td>565.43</td>\n",
       "      <td>25.14</td>\n",
       "      <td>859.14</td>\n",
       "      <td>25.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.16</td>\n",
       "      <td>869.01</td>\n",
       "      <td>147.71</td>\n",
       "      <td>18.17</td>\n",
       "      <td>217.25</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>1475.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>368.75</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.50</td>\n",
       "      <td>3669.00</td>\n",
       "      <td>606.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>917.25</td>\n",
       "      <td>19.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3733.00</td>\n",
       "      <td>617.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>933.25</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>3811.50</td>\n",
       "      <td>627.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>952.88</td>\n",
       "      <td>23.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3887.00</td>\n",
       "      <td>641.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>971.75</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count         7.00             7.00             7.00                     7.00   \n",
       "mean         -2.00          3436.57           565.43                    25.14   \n",
       "std           2.16           869.01           147.71                    18.17   \n",
       "min          -5.00          1475.00           232.00                    15.00   \n",
       "25%          -3.50          3669.00           606.50                    17.00   \n",
       "50%          -2.00          3733.00           617.00                    19.00   \n",
       "75%          -0.50          3811.50           627.50                    21.00   \n",
       "max           1.00          3887.00           641.00                    66.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count              7.00                       7.00  \n",
       "mean             859.14                      25.71  \n",
       "std              217.25                      14.99  \n",
       "min              368.75                      15.00  \n",
       "25%              917.25                      19.50  \n",
       "50%              933.25                      20.00  \n",
       "75%              952.88                      23.50  \n",
       "max              971.75                      59.00  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f511307",
   "metadata": {},
   "source": [
    "#### Chunking Text for Embedding and Retrieval\n",
    "\n",
    "Chunking text into manageable segments is essential for effective processing in a Retrieval-Augmented Generation (RAG) pipeline.\n",
    "\n",
    "**LangChain** provides tools to handle this chunking, making it easier to organize content to fit within the embedding model’s context window. Proper chunking ensures that the context passed to the LLM is focused and relevant, leading to more accurate and precise responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6821e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10  # Experiment with the number\n",
    "\n",
    "\n",
    "# Create a funcion to split lists of texts recursively into chunk size\n",
    "# e.g. [20]->[10,10] or [25] -> [10,10,5]\n",
    "def split_list(\n",
    "    input_list: list[str], slice_size: int = num_sentence_chunk_size\n",
    ") -> list[list[str]]:\n",
    "    return [\n",
    "        input_list[i : i + slice_size] for i in range(0, len(input_list), slice_size)\n",
    "    ]\n",
    "\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd09a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 40440.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop throough ppers and texts and split sentencds into chunk\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(\n",
    "        input_list=item[\"sentences\"], slice_size=num_sentence_chunk_size\n",
    "    )\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a3f7444",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39msample(pages_and_texts, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b77e78e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3436.57</td>\n",
       "      <td>565.43</td>\n",
       "      <td>25.14</td>\n",
       "      <td>859.14</td>\n",
       "      <td>25.71</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.16</td>\n",
       "      <td>869.01</td>\n",
       "      <td>147.71</td>\n",
       "      <td>18.17</td>\n",
       "      <td>217.25</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>1475.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>368.75</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.50</td>\n",
       "      <td>3669.00</td>\n",
       "      <td>606.50</td>\n",
       "      <td>17.00</td>\n",
       "      <td>917.25</td>\n",
       "      <td>19.50</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>3733.00</td>\n",
       "      <td>617.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>933.25</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.50</td>\n",
       "      <td>3811.50</td>\n",
       "      <td>627.50</td>\n",
       "      <td>21.00</td>\n",
       "      <td>952.88</td>\n",
       "      <td>23.50</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>3887.00</td>\n",
       "      <td>641.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>971.75</td>\n",
       "      <td>59.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count         7.00             7.00             7.00                     7.00   \n",
       "mean         -2.00          3436.57           565.43                    25.14   \n",
       "std           2.16           869.01           147.71                    18.17   \n",
       "min          -5.00          1475.00           232.00                    15.00   \n",
       "25%          -3.50          3669.00           606.50                    17.00   \n",
       "50%          -2.00          3733.00           617.00                    19.00   \n",
       "75%          -0.50          3811.50           627.50                    21.00   \n",
       "max           1.00          3887.00           641.00                    66.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count              7.00                       7.00        7.00  \n",
       "mean             859.14                      25.71        2.86  \n",
       "std              217.25                      14.99        1.46  \n",
       "min              368.75                      15.00        2.00  \n",
       "25%              917.25                      19.50        2.00  \n",
       "50%              933.25                      20.00        2.00  \n",
       "75%              952.88                      23.50        3.00  \n",
       "max              971.75                      59.00        6.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef9e8f",
   "metadata": {},
   "source": [
    "### Splitting and Embedding Text Chunks\n",
    "\n",
    "Each chunk of text is split into individual items and embedded as its own unique numerical representation. This process helps ensure that each segment of content is distinct and appropriately prepared for retrieval and analysis in the RAG pipeline.\n",
    "\n",
    "The following code performs this function by:\n",
    "\n",
    "1. **Combining Sentences into Chunks**: Each chunk is created by joining related sentences into a paragraph-like structure.\n",
    "2. **Cleaning and Formatting**: Simple formatting (e.g., adding spaces after full stops) ensures consistency and readability within each chunk.\n",
    "3. **Generating Statistics**: The code calculates character count, word count, and an estimated token count for each chunk, which can be useful for managing context windows and model constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e30b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 3515.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# split each chunk into its own item\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(\n",
    "            r\"\\.([A-Z])\", r\". \\1\", joined_sentence_chunk\n",
    "        )  # \".A\" -> \". A\" for any full-stop/capital letter combo\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len(\n",
    "            [word for word in joined_sentence_chunk.split(\" \")]\n",
    "        )\n",
    "        chunk_dict[\"chunk_token_count\"] = (\n",
    "            len(joined_sentence_chunk) / 4\n",
    "        )  # 1 token = ~4 characters\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# Number of chunks we have\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c038ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39msample(pages_and_chunks, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31e50ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.60</td>\n",
       "      <td>1188.70</td>\n",
       "      <td>184.50</td>\n",
       "      <td>297.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.28</td>\n",
       "      <td>757.77</td>\n",
       "      <td>119.79</td>\n",
       "      <td>189.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.00</td>\n",
       "      <td>189.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>47.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.25</td>\n",
       "      <td>295.75</td>\n",
       "      <td>42.25</td>\n",
       "      <td>73.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.50</td>\n",
       "      <td>1527.50</td>\n",
       "      <td>231.50</td>\n",
       "      <td>381.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1798.75</td>\n",
       "      <td>284.75</td>\n",
       "      <td>449.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2263.00</td>\n",
       "      <td>349.00</td>\n",
       "      <td>565.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count        20.00             20.00             20.00              20.00\n",
       "mean         -1.60           1188.70            184.50             297.18\n",
       "std           2.28            757.77            119.79             189.44\n",
       "min          -5.00            189.00             26.00              47.25\n",
       "25%          -3.25            295.75             42.25              73.94\n",
       "50%          -1.50           1527.50            231.50             381.88\n",
       "75%           1.00           1798.75            284.75             449.69\n",
       "max           1.00           2263.00            349.00             565.75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "390b8981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 55 The author ...</td>\n",
       "      <td>1204</td>\n",
       "      <td>194</td>\n",
       "      <td>301.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5</td>\n",
       "      <td>Under the earlier appellation, John Unsworth h...</td>\n",
       "      <td>1587</td>\n",
       "      <td>235</td>\n",
       "      <td>396.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5</td>\n",
       "      <td>Crucially, there are digital humanities center...</td>\n",
       "      <td>845</td>\n",
       "      <td>129</td>\n",
       "      <td>211.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...</td>\n",
       "      <td>1471</td>\n",
       "      <td>228</td>\n",
       "      <td>367.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>We could attempt to refine this “outlook” quan...</td>\n",
       "      <td>2263</td>\n",
       "      <td>349</td>\n",
       "      <td>565.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0           -5  ADE Bulletin ◆ Number 150, 2010 55 The author ...   \n",
       "1           -5  Under the earlier appellation, John Unsworth h...   \n",
       "2           -5  Crucially, there are digital humanities center...   \n",
       "3           -4  ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...   \n",
       "4           -4  We could attempt to refine this “outlook” quan...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "0              1204               194             301.00  \n",
       "1              1587               235             396.75  \n",
       "2               845               129             211.25  \n",
       "3              1471               228             367.75  \n",
       "4              2263               349             565.75  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "492c0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_number                                     sentence_chunk  \\\n",
      "0           -5  ADE Bulletin ◆ Number 150, 2010 55 The author ...   \n",
      "1           -5  Under the earlier appellation, John Unsworth h...   \n",
      "2           -5  Crucially, there are digital humanities center...   \n",
      "3           -4  ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...   \n",
      "4           -4  We could attempt to refine this “outlook” quan...   \n",
      "\n",
      "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
      "0              1204               194             301.00  \n",
      "1              1587               235             396.75  \n",
      "2               845               129             211.25  \n",
      "3              1471               228             367.75  \n",
      "4              2263               349             565.75  \n",
      "count     20.00000\n",
      "mean     297.17500\n",
      "std      189.44172\n",
      "min       47.25000\n",
      "25%       73.93750\n",
      "50%      381.87500\n",
      "75%      449.68750\n",
      "max      565.75000\n",
      "Name: chunk_token_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())  # Displays the first few rows of the DataFrame\n",
    "print(\n",
    "    df[\"chunk_token_count\"].describe()\n",
    ")  # Shows statistics for the chunk_token_count column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "738b9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks found with token count <= 70: 5\n",
      "Chunk token count: 60.5 | Text: 2 Nov. 2010. French, Amanda. “Make ‘10’ Louder; or, The Amplification of Scholarly Communication.”­Amandafrench​ .net. French, 30 Dec. 2009. Web.2 Aug. 2010. Howard, Jennifer. “The MLA Convention in Translation.”Chronicle of Higher Education.\n",
      "Chunk token count: 56.75 | Text: Message to the author.5 Apr. 2010. E‑mail. ———. “What Is Humanities Computing and What Is Not?”Graduate School of Library and Information Sciences. Illinois Informatics Inst.,U of Illinois, Urbana, 8 Nov. 2002. Web.2 Aug. 2010.\n",
      "Chunk token count: 54.5 | Text: Chronicle of Higher Education. Chron­ icle of Higher Educ.,28 Dec. 2009. Web.2 Aug. 2010. Selfe, Cynthia. “Computers in En­glish Departments: The Rhetoric of Technopower.”ADE Bulletin 90 (1988): 63–67. Web.2 Aug. 2010.\n",
      "Chunk token count: 47.25 | Text: Chronicle of Higher Educ.,31 Dec. 2009. Web.2 Aug. 2010. McCarty, Willard. Humanities Computing. New York: Palgrave, 2005. Print. Pannapacker, William. “The MLA and the Digital Humanities.”\n",
      "Chunk token count: 63.25 | Text: Svensson, Patrik. “Humanities Computing as Digital Humanities.”Digital Humanities Quarterly 3.3 (2009): n. pag. Web.2 Aug. 2010. ———. “The Landscape of Digital Humanities.”Digital Humanities Quarterly 4.1 (2010): n. pag. Web.2 Aug. 2010. Unsworth, John.\n"
     ]
    }
   ],
   "source": [
    "# Filter chunks of text for short chunks as they may not contain much useful information\n",
    "# Show random chunks with under 70 tokens in length\n",
    "# You may need to adjust the number of tokens. The below code has been adjusted to check whether tokens of your expected count exists in the DatafFrame.\n",
    "\n",
    "# Set min_token_length to filter out short chunks\n",
    "min_token_length = 70\n",
    "\n",
    "# Filter and check the DataFrame\n",
    "filtered_df = df[df[\"chunk_token_count\"] <= min_token_length]\n",
    "print(\n",
    "    f\"Number of chunks found with token count <= {min_token_length}: {len(filtered_df)}\"\n",
    ")\n",
    "\n",
    "if not filtered_df.empty:\n",
    "    sample_size = min(5, len(filtered_df))\n",
    "    for _, row in filtered_df.sample(sample_size).iterrows():\n",
    "        print(\n",
    "            f'Chunk token count: {row[\"chunk_token_count\"]} | Text: {row[\"sentence_chunk\"]}'\n",
    "        )\n",
    "else:\n",
    "    print(f\"No chunks found with token count <= {min_token_length}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44b299ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -5,\n",
       "  'sentence_chunk': 'ADE Bulletin ◆ Number 150, 2010 55 The author is associate professor of English and associate director of the Maryland Institute for Technology in the Hu\\xad manities at the University of Maryland. A version of this article was presented at the 2010 ADE Sum\\xad mer Seminar East in Adelphi, Maryland. People who say that the last battles of the computer revolution in En\\xadglish departments have been fought and won don’t know what they’re talking about. If our current use of computers in En\\xadglish studies is marked by any common theme at all, it is experimentation at the most basic level. As a pro\\xad fession, we are just learning how to live with computers, just beginning to integrate these machines effectively into writing- and reading-\\xadintensive courses, just starting to consider the implications of the multilayered literacy associated with computers.\\x08 —Cynthia Selfe What is (or are) the “digital humanities,” aka “humanities computing”?It’s tempt\\xad ing to say that whoever asks the question has not gone looking very hard for an answer. “What is digital humanities?”essays like this one are already genre pieces. Willard McCarty has been contributing papers on the subject for years (a mono\\xad graph too).',\n",
       "  'chunk_char_count': 1204,\n",
       "  'chunk_word_count': 194,\n",
       "  'chunk_token_count': 301.0},\n",
       " {'page_number': -5,\n",
       "  'sentence_chunk': 'Under the earlier appellation, John Unsworth has advised us “what is humanities computing and what is not.”Most recently Patrik Svensson has been publishing a series of well-\\xaddocumented articles on multiple aspects of the topic, including the lexical shift from humanities computing to digital humanities. More\\xad over, as Cynthia Selfe in an ADE Bulletin from 1988 reminds us, computers have been part of our disciplinary lives for well over two decades now. During this time digital humanities has accumulated a robust professional apparatus that is probably more rooted in En\\xadglish than any other departmental home. The contours of this professional apparatus are easily discoverable. An organiza\\xad tion called the Alliance of Digital Humanities Organizations hosts a well-\\xadattended annual international conference called Digital Humanities (it grew out of an earlier annual series of conferences, hosted jointly by the Association for Computers and the Humanities and the Association for Literary and Linguistic Computing since 1989). There is Blackwell’s Companion to Digital Humanities. There is a book series (yes, a book series), Topics in the Digital Humanities, from the University of Illinois Press. There is a refereed journal called Digital Humanities Quarterly, one of several that serve the field, including a newer publication, Digital Studies / Le champ numérique, sponsored by the Canadian Society for Digital Humanities (Société pour l’Étude des Médias Interactifs). The University of Victoria hosts the annual Digital Humani\\xad ties Summer Institute to train new scholars.',\n",
       "  'chunk_char_count': 1587,\n",
       "  'chunk_word_count': 235,\n",
       "  'chunk_token_count': 396.75}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter Dataframe for rows with under 70 tokens\n",
    "# You will need to adjust the number of tokens depending on your DataFrame structure\n",
    "\n",
    "pages_and_chunks_over_min_token_len = df[\n",
    "    df[\"chunk_token_count\"] > min_token_length\n",
    "].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e385295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -4,\n",
       "  'sentence_chunk': 'ADE Bulletin ◆ Number 150, 2010 56 What Is Digital Humanities and What’s It Doing in En\\xadglish Departments?Matthew G. Kirschenbaum strategic plan and curriculum-\\xaddevelopment document, every hiring request, and so forth that invokes the term. Or the countless times the question has been visited on electronic discussion lists, blogs, Facebook walls, and Twitter feeds, contributing all the flames and exhortations, celebrations and screeds one could wish to read. We could also, of course, simply Google the question. Google takes us to Wikipe\\xad dia, and what we find there is not bad: The digital humanities, also known as humanities computing, is a field of study, research, teaching, and invention concerned with the intersection of computing and the disciplines of the humanities. It is methodological by nature and interdisciplinary in scope. It involves investigation, analysis, synthesis and presentation of information in electronic form. It studies how these media affect the disciplines in which they are used, and what these disciplines have to contribute to our knowledge of computing. As a working definition this serves as well as any I’ve seen, which is not surprising since a glance at the page’s View History tab reveals individuals closely associated with the digital humanities as contributors. At its core, then, digital humanities is more akin to a common methodological outlook than an investment in any one specific set of texts or even technologies.',\n",
       "  'chunk_char_count': 1471,\n",
       "  'chunk_word_count': 228,\n",
       "  'chunk_token_count': 367.75}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45649f6d",
   "metadata": {},
   "source": [
    "#### Embedding Text Chunks\n",
    "\n",
    "see https://vickiboykis.com/what_are_embeddings/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcd183e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "## Note: Downgraded NumPy to version <2 for compatibility with sentence-transformers.\n",
    "# NumPy 2.x versions are currently not fully supported by sentence-transformers and may cause errors.\n",
    "# This downgrade ensures stable integration when encoding embeddings.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7594ab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentence Transformer library provides an easy way to create embeddings.\n",
      "Embedding: [-3.44286561e-02  2.95328666e-02 -2.33643446e-02  5.57257347e-02\n",
      " -2.19098609e-02 -6.47061458e-03  1.02848643e-02 -6.57803416e-02\n",
      "  2.29718257e-02 -2.61120778e-02  3.80420648e-02  5.61403073e-02\n",
      " -3.68746556e-02  1.52787985e-02  4.37020436e-02 -5.19723631e-02\n",
      "  4.89479713e-02  3.58103635e-03 -1.29750641e-02  3.54384817e-03\n",
      "  4.23262678e-02  3.52606401e-02  2.49402598e-02  2.99176928e-02\n",
      " -1.99382566e-02 -2.39752196e-02 -3.33364634e-03 -4.30450402e-02\n",
      "  5.72014488e-02 -1.32517964e-02 -3.54478136e-02 -1.13936029e-02\n",
      "  5.55561408e-02  3.61095602e-03  8.88526756e-07  1.14027224e-02\n",
      " -3.82229947e-02 -2.43544439e-03  1.51314372e-02 -1.32716275e-04\n",
      "  5.00659943e-02 -5.50876446e-02  1.73444748e-02  5.00959530e-02\n",
      " -3.75959128e-02 -1.04463520e-02  5.08322231e-02  1.24861291e-02\n",
      "  8.67377520e-02  4.64142784e-02 -2.10690200e-02 -3.90251316e-02\n",
      "  1.99694769e-03 -1.42345643e-02 -1.86794661e-02  2.82669645e-02\n",
      " -4.17522304e-02 -3.59939574e-03 -1.30826635e-02  3.91671471e-02\n",
      " -2.92913746e-02  4.63230014e-02  6.12684386e-03 -3.85694355e-02\n",
      "  6.66883588e-02 -1.42419068e-02 -6.49578124e-02  4.04557446e-03\n",
      " -3.01187672e-03  6.58981875e-02  7.93331023e-03 -2.52185259e-02\n",
      " -3.52043137e-02 -2.06171945e-02  3.65961865e-02  2.41233762e-02\n",
      " -4.23979610e-02 -2.37271562e-02  7.19451830e-02  3.18896845e-02\n",
      "  8.56764149e-03  5.01809120e-02  3.06092668e-02 -3.81284580e-02\n",
      " -3.40645052e-02 -4.32109982e-02  5.26518449e-02 -4.27095443e-02\n",
      " -3.30608524e-02 -2.80990507e-02 -8.63213278e-03  3.27507518e-02\n",
      "  3.98531742e-02 -2.80643590e-02  1.62000656e-02  1.64635852e-02\n",
      " -7.26301894e-02 -2.35976260e-02 -4.99444222e-03 -2.43375376e-02\n",
      "  6.63573444e-02  1.01700881e-02 -7.33341882e-03  1.01678008e-02\n",
      " -8.24312717e-02  5.06568588e-02  1.54305692e-03 -3.88789619e-03\n",
      " -2.68746950e-02 -2.70628091e-02 -4.45155501e-02 -9.93511453e-03\n",
      " -6.68739229e-02  1.33291520e-02 -1.38136689e-02 -7.60722086e-02\n",
      " -4.59486172e-02  5.82300872e-02 -3.41541544e-02  2.06777491e-02\n",
      "  5.75290341e-03  1.62674468e-02  1.88210346e-02  2.27290280e-02\n",
      " -7.16705620e-03  1.31421592e-02 -2.34097652e-02 -3.14957760e-02\n",
      " -1.90285202e-02  2.24106833e-02 -2.75777988e-02  5.19171469e-02\n",
      "  6.12935387e-02 -3.74241848e-03 -4.91759256e-02  4.43299627e-03\n",
      "  2.02150773e-02 -3.07915062e-02  3.44955437e-02  3.42498980e-02\n",
      " -7.23882637e-04  2.76552700e-02  8.57944542e-04 -4.65564169e-02\n",
      "  6.29549026e-02 -4.82681580e-03  1.12508703e-02 -4.57350872e-02\n",
      "  2.62186881e-02  2.94705965e-02 -4.70293947e-02  1.26509160e-01\n",
      "  1.09374179e-02 -3.88611816e-02 -6.29502758e-02 -2.97410339e-02\n",
      "  7.95470998e-02  5.15913256e-02  5.60819395e-02 -1.68494117e-02\n",
      "  4.59670052e-02  5.02502880e-05 -1.38017656e-02  1.84812397e-02\n",
      " -1.42344609e-02 -1.03216590e-02 -1.79739837e-02 -1.39032500e-02\n",
      "  3.46015650e-03  8.58673230e-02 -1.29174506e-02  7.49304593e-02\n",
      "  6.11051405e-03  1.45746553e-02  2.25933865e-02  6.90806881e-02\n",
      "  5.59253134e-02  5.44433435e-03  8.17072988e-02  3.58046554e-02\n",
      " -4.49425243e-02  2.65793018e-02 -4.30802666e-02  5.07438816e-02\n",
      "  1.58738159e-02  3.93476821e-02 -1.61547549e-02  7.93661997e-02\n",
      "  4.35209228e-03  1.11144464e-02 -2.07478069e-02 -3.64702046e-02\n",
      "  1.79305598e-02 -4.53404561e-02 -1.21980999e-02  4.42192554e-02\n",
      " -3.85862365e-02  4.27426808e-02 -2.27928118e-04 -6.03185296e-02\n",
      "  1.44641066e-03  3.66891176e-02 -2.83555593e-04  7.67654628e-02\n",
      "  4.95438688e-02  1.62606258e-02  2.26804167e-02 -3.24033611e-02\n",
      " -3.86327580e-02  7.82949999e-02  2.78974958e-02 -2.20212322e-02\n",
      " -2.95080394e-02 -7.43439049e-02  4.18463014e-02 -2.27421313e-03\n",
      "  9.15870722e-03 -2.64815688e-02 -1.25546576e-02  2.28404924e-02\n",
      "  6.82077780e-02 -3.07935998e-02  3.61645967e-02  3.87404934e-02\n",
      " -2.34643295e-02 -1.86181515e-02 -1.29856548e-04  2.78771520e-02\n",
      "  1.14772022e-02  3.79705913e-02 -1.60052311e-02  7.01069310e-02\n",
      "  6.32945448e-02 -3.99301462e-02 -4.42786403e-02  5.96374348e-02\n",
      " -2.23135632e-02 -7.57413730e-02  1.49409100e-02 -9.69460532e-02\n",
      "  2.42266413e-02  3.49750184e-03  1.57967361e-03 -1.62706375e-02\n",
      " -1.31779332e-02 -5.74738439e-03  8.57103691e-02 -4.42351885e-02\n",
      " -5.16821165e-03  3.88116837e-02  3.97148654e-02 -2.85581164e-02\n",
      " -1.36332028e-03  5.21436073e-02  1.33008342e-02 -1.98847149e-02\n",
      " -3.53314616e-02 -3.27012711e-03  3.66954058e-02 -2.43318570e-03\n",
      " -2.35368740e-02  2.37296186e-02 -4.22030548e-03 -2.85154656e-02\n",
      " -9.95514635e-03  2.10746247e-02 -2.99481452e-02 -4.54378016e-02\n",
      "  2.57443311e-03  2.40146127e-02 -9.36570298e-03  3.95621639e-03\n",
      "  2.72044111e-02  1.66734904e-02  3.04440148e-02 -5.11822291e-02\n",
      "  1.59915369e-02 -2.37711240e-04  2.27038916e-02  4.44445089e-02\n",
      " -6.36408776e-02 -3.83594297e-02 -4.00811657e-02  2.31166314e-02\n",
      " -2.28346139e-02  5.22318445e-02 -5.64015508e-02 -5.54196490e-03\n",
      " -3.16336155e-02 -8.85502528e-03  1.54491141e-02  1.30278673e-02\n",
      "  3.72903273e-02 -3.58289927e-02 -1.00853695e-02  1.23442719e-02\n",
      "  7.60784447e-02  3.69417779e-02 -9.44152102e-03  5.70524484e-02\n",
      "  5.23618497e-02 -1.17083313e-02 -1.56439189e-02  6.22282177e-03\n",
      " -1.06243631e-02  5.60463816e-02 -5.64208766e-03  5.41884685e-03\n",
      " -1.21085048e-02  1.23996679e-02  2.18709488e-03 -9.17427335e-03\n",
      " -1.89263783e-02  3.57193761e-02 -5.53161278e-03 -7.21392920e-03\n",
      " -6.24067849e-03 -4.90312558e-03 -3.01039666e-02 -2.73905396e-02\n",
      "  3.76886241e-02 -3.26242793e-04  3.61380801e-02 -5.17626926e-02\n",
      " -3.06851957e-02 -3.95019241e-02 -3.99090312e-02 -3.96709554e-02\n",
      "  6.23496957e-02 -7.13259168e-03  5.07611490e-04 -1.15799531e-02\n",
      " -7.76437996e-03 -3.30222808e-02  2.27072109e-02  4.39099185e-02\n",
      "  1.80926006e-02  1.33063672e-02  1.04865106e-02 -2.82455217e-02\n",
      " -1.57835297e-02 -2.82920748e-02 -2.41274256e-02 -4.84205335e-02\n",
      " -8.66245758e-03  2.37213932e-02  1.99321564e-02 -1.35324458e-02\n",
      " -2.93465927e-02  1.42494235e-02 -1.25415679e-02 -1.46438098e-02\n",
      " -1.33557254e-02  1.02691865e-02 -5.04000299e-02  6.88536912e-02\n",
      "  4.72585745e-02  1.26609206e-03 -1.89663880e-02 -2.18124595e-03\n",
      "  6.67324737e-02 -2.33003460e-02 -4.59404625e-02  1.23993447e-03\n",
      " -5.13819121e-02 -3.30483429e-02 -1.82183529e-03 -4.85388935e-02\n",
      "  2.42682789e-02  4.89646755e-03 -3.73754720e-03  9.66766197e-03\n",
      " -1.69690140e-02  8.71259198e-02  5.44295460e-02 -3.85265276e-02\n",
      "  3.44931372e-02 -3.72254997e-02  3.47704254e-02  3.20372591e-03\n",
      "  3.44035104e-02 -1.16729096e-01 -4.00709659e-02 -7.51273753e-03\n",
      " -3.64854597e-02  4.74884138e-02  6.11870084e-03  4.82693966e-03\n",
      " -9.75745916e-02  1.94991715e-02  2.06659548e-02  5.37244827e-02\n",
      " -3.83448116e-02 -1.50264483e-02 -4.93642688e-02  1.69349257e-02\n",
      " -1.32873841e-02 -3.25810462e-02 -1.35620162e-02  7.58301467e-05\n",
      " -5.32805659e-02 -6.10713176e-02 -1.14890728e-02 -3.04298140e-02\n",
      " -6.29046783e-02  3.11574433e-02 -4.25547035e-03  5.35520129e-02\n",
      "  5.80757798e-04 -3.18181813e-02 -7.51201510e-02 -2.28261836e-02\n",
      " -6.52606189e-02  2.64531188e-02  3.56256254e-02 -2.42591240e-02\n",
      " -2.48210877e-02  7.10834470e-03  3.44615541e-02 -3.58824469e-02\n",
      " -2.35385876e-02  2.89773252e-02  9.04023573e-02 -3.30273318e-03\n",
      "  9.67263244e-03 -4.82161269e-02  1.33224977e-02  2.13714503e-02\n",
      "  4.24260125e-02  2.80175209e-02 -1.16784004e-02 -8.52965051e-04\n",
      "  3.61303869e-03  4.90847997e-05 -4.21287678e-02 -3.83800045e-02\n",
      "  2.59826519e-02 -1.66465025e-02  4.53917794e-02 -8.60693231e-02\n",
      " -3.78084257e-02  5.70828728e-02  2.29125712e-02  3.66921686e-02\n",
      "  1.06494874e-02  1.90632399e-02 -1.82972988e-03 -5.97028695e-02\n",
      " -1.24359522e-02  1.07637616e-02  1.96661986e-02  2.29673330e-02\n",
      " -2.30668429e-02  5.48702851e-02  3.38971131e-02  1.75856799e-02\n",
      " -2.28889864e-02 -3.06942668e-02 -4.81055379e-02  7.13957520e-03\n",
      "  2.17535179e-02  8.45424645e-03  1.33396164e-02 -4.54223081e-02\n",
      "  3.38963084e-02  4.58740629e-02  3.46707925e-02 -7.65073299e-02\n",
      " -1.93071608e-02  9.84592829e-03 -1.36193642e-02  1.15063712e-02\n",
      "  3.78279090e-02 -6.25107996e-03 -3.61669017e-03 -6.28121793e-02\n",
      "  3.25885415e-02  2.00627223e-02 -6.75870776e-02  1.74651761e-02\n",
      " -5.44601381e-02 -2.69646905e-02 -3.39342989e-02  9.15186666e-03\n",
      " -6.85482379e-03  1.50180673e-02 -1.14632256e-01 -3.48746926e-02\n",
      " -5.34086674e-02  2.59111673e-02  4.46101576e-02  1.63094215e-02\n",
      "  8.70553590e-03 -2.26442460e-02 -2.66445577e-02  6.84182206e-03\n",
      "  1.11482367e-02  5.68693653e-02  4.96933721e-02 -1.27541441e-02\n",
      " -1.26163177e-02  2.45030131e-02 -3.40678021e-02 -1.06380414e-02\n",
      " -7.31094256e-02 -5.42687438e-03 -3.50816213e-02 -1.15438830e-02\n",
      " -2.00235415e-02 -1.32712713e-02 -4.83775698e-02  4.29345034e-02\n",
      " -2.42103357e-02  5.23327999e-02 -2.63345223e-02  3.02770454e-03\n",
      "  7.88600966e-02 -9.47285350e-03  5.09274378e-02 -6.98979245e-03\n",
      " -2.83143409e-02  6.09138831e-02  6.34607151e-02 -6.49071410e-02\n",
      " -1.86333656e-02  4.04769927e-03  1.80158224e-02 -3.19798030e-02\n",
      " -4.36901115e-02  2.82262769e-02 -2.02955622e-02 -1.79637398e-03\n",
      "  2.56271902e-02  6.55631395e-03 -5.57637885e-02 -1.39311980e-02\n",
      "  3.88334803e-02  3.77677418e-02 -3.07319164e-02 -1.68724079e-02\n",
      " -3.49365324e-02 -6.65668845e-02 -1.88083574e-02  3.86462472e-02\n",
      " -1.54485935e-02  9.48597305e-03 -1.73503533e-02  8.04663263e-03\n",
      "  1.75369903e-02 -2.30519716e-02 -1.32560497e-02  3.37193795e-02\n",
      " -1.54417455e-02 -6.87238574e-02 -3.28853019e-02 -4.49871129e-33\n",
      " -4.44906801e-02  9.54691228e-03 -2.57224254e-02 -3.21281962e-02\n",
      " -4.30242438e-03 -4.26218519e-03  5.16676623e-03  2.25371849e-02\n",
      "  2.49413140e-02  3.24430913e-02  9.34811402e-03 -2.73894966e-02\n",
      "  1.38996756e-02  1.00506870e-02 -1.26833573e-03  2.90706288e-02\n",
      "  2.60552447e-02 -1.68451052e-02  1.71561204e-02  1.25806285e-02\n",
      "  1.24600055e-02  3.60123143e-02  4.09958176e-02 -3.05390079e-02\n",
      " -2.42153909e-02  1.16510801e-02 -8.61148816e-03 -3.64995445e-03\n",
      "  3.25473435e-02  4.22551446e-02 -2.76540238e-02  2.32557151e-02\n",
      " -2.10831258e-02  4.25280519e-02 -1.60155892e-02  6.31458983e-02\n",
      " -4.40687500e-02 -5.13205398e-03  4.02368829e-02 -2.52309293e-02\n",
      " -2.02982649e-02 -4.01854813e-02 -3.42488475e-02 -4.86407243e-02\n",
      "  4.07062843e-02  1.19460104e-02  3.70717160e-02 -1.10960577e-03\n",
      " -1.08807199e-02  1.28650162e-02 -8.01075250e-02 -8.55961174e-04\n",
      "  8.65100417e-03  2.05036830e-02  2.53296141e-02 -8.17070808e-03\n",
      "  6.28591923e-04 -3.34684947e-03 -2.97054066e-03 -8.26582871e-03\n",
      " -3.67429480e-02  3.16992849e-02  2.49395408e-02 -4.95019816e-02\n",
      " -4.88927737e-02  6.75727800e-02 -3.79922912e-02 -3.87111604e-02\n",
      " -7.73420697e-03  4.97960560e-02  2.09199935e-02  3.35242115e-02\n",
      "  5.47627360e-02  6.31318539e-02 -1.58095602e-02  2.19913125e-02\n",
      " -1.67724639e-02 -1.54925045e-02  2.51924787e-02 -3.56685440e-03\n",
      "  3.17917429e-02  3.06093413e-02  2.60381885e-02 -1.52969658e-02\n",
      " -1.50790336e-02  1.22895548e-02  5.31405443e-03 -6.28142804e-02\n",
      "  3.58325243e-02  8.64118896e-03 -3.25661637e-02  9.51272901e-03\n",
      "  3.60868126e-02 -1.93802789e-02 -2.90086446e-03  2.36174725e-02\n",
      " -6.19429210e-03  2.53082123e-02 -9.00894590e-03  3.83066386e-02\n",
      "  7.40727549e-03 -3.88698094e-02 -7.62193056e-04 -1.19214002e-02\n",
      "  2.58010589e-02  1.50567116e-02  2.97986269e-02 -1.24886511e-02\n",
      " -7.63765574e-02  7.84257601e-04 -4.59647272e-03 -5.96700720e-02\n",
      " -4.99217175e-02  3.65763297e-03 -1.55270211e-02  2.41611451e-02\n",
      " -5.76895196e-03 -1.69782876e-03  3.52600403e-02 -1.41619612e-02\n",
      " -2.79697869e-02 -2.50185672e-02  4.09227386e-02  3.31035107e-02\n",
      " -2.88113207e-02 -1.83183439e-02 -4.28755879e-02  4.02016751e-02\n",
      "  4.59586270e-02 -6.20828196e-02  1.84501838e-02  1.13506324e-03\n",
      "  1.72663263e-07  2.86143925e-02  5.50686643e-02  4.52570170e-02\n",
      "  5.29318117e-03 -1.29606724e-02 -2.52387952e-02  1.48602417e-02\n",
      "  6.78400621e-02 -3.56872473e-03  1.65683478e-02  1.49408206e-02\n",
      " -1.64327361e-02  1.32763907e-02  2.84507163e-02 -1.37935326e-01\n",
      "  2.26399787e-02 -3.04838233e-02 -2.96503734e-02 -4.93083447e-02\n",
      " -1.45468973e-02  1.27221689e-01  1.06428333e-01  4.55490611e-02\n",
      "  4.17893715e-02 -1.05863316e-02 -2.93935556e-02  3.29429954e-02\n",
      "  1.14067066e-02 -3.86650972e-02 -2.50283591e-02 -2.86876876e-02\n",
      " -2.30519008e-02 -1.87885538e-02 -7.56757334e-03 -3.12078334e-02\n",
      "  2.19139755e-02  2.03541387e-02  1.14066992e-03 -5.82867954e-03\n",
      "  7.71838473e-03 -4.40828800e-02 -1.21653117e-02 -2.23599989e-02\n",
      " -2.46035326e-02  5.00243232e-02 -6.77434877e-02 -1.67534146e-02\n",
      " -4.29059640e-02 -3.12047098e-02  2.83358395e-02  6.48823613e-03\n",
      " -2.46221423e-02 -4.35099341e-02  1.45791192e-02  4.03499603e-02\n",
      "  4.33951057e-03 -1.14601208e-02 -7.68447518e-02 -4.44949530e-02\n",
      "  3.59258265e-03 -1.57844927e-02 -1.04557360e-02 -2.14963965e-02\n",
      " -3.05430610e-02  5.50825559e-02  6.99721160e-04  1.58236176e-02\n",
      "  1.89766286e-34  4.58320230e-02  1.93463005e-02  4.65045460e-02\n",
      "  6.44745752e-02  4.34260182e-02 -3.92567590e-02  1.20961478e-04\n",
      "  1.26640350e-02  1.90869384e-02 -6.96959198e-02 -3.12183201e-02]\n",
      "\n",
      "Sentence: Sentence embedding is part of the process.\n",
      "Embedding: [-3.53507837e-03 -5.53638395e-03 -3.69562767e-02  3.87736335e-02\n",
      " -9.62251797e-03  3.50067578e-02 -1.35068491e-04 -2.28744112e-02\n",
      " -1.96182877e-02 -2.32768636e-02  4.85038161e-02  1.10450629e-02\n",
      " -7.31702754e-03 -4.42296267e-03  5.11317775e-02 -4.66298088e-02\n",
      "  4.77613471e-02  2.70530097e-02 -8.66962690e-03  7.02187233e-03\n",
      "  2.24151579e-03 -1.18587713e-03  4.34747338e-02  9.52906534e-03\n",
      " -1.16187222e-02 -3.08199506e-02 -1.77195352e-02 -3.15772593e-02\n",
      " -1.34936406e-03 -3.83059382e-02 -4.09074351e-02  1.49147362e-02\n",
      "  2.56084912e-02  1.51801808e-02  1.41122177e-06 -2.91363616e-03\n",
      " -1.40442289e-02 -3.81971374e-02 -1.30133200e-02  6.03862628e-02\n",
      "  3.90656739e-02  4.51016473e-03  2.85765193e-02  5.53415483e-03\n",
      " -2.53520068e-02 -1.54515896e-02  6.99110925e-02  7.76036829e-02\n",
      "  6.33104593e-02  5.83751574e-02 -2.43175845e-03 -5.52815050e-02\n",
      "  3.54797277e-03 -1.70721281e-02  1.69574432e-02  3.00869383e-02\n",
      "  2.62050740e-02 -1.99157391e-02 -1.69948693e-02  4.88708988e-02\n",
      " -6.66619390e-02  5.01527861e-02  2.95059718e-02  1.17976330e-02\n",
      "  2.58778837e-02  2.79006944e-03  1.90477837e-02 -1.93801764e-02\n",
      "  1.47219496e-02  1.09050320e-02 -4.96239308e-03 -3.99753489e-02\n",
      " -5.64259803e-03  2.37395782e-02 -2.08357160e-04 -8.36080289e-04\n",
      " -5.62348552e-02 -1.12452861e-02  2.47111563e-02  4.51456308e-02\n",
      "  2.71390770e-02 -2.21477402e-03  1.50302779e-02 -4.21426855e-02\n",
      "  1.42040290e-02  2.18034536e-02  7.63183646e-03 -5.10464609e-02\n",
      " -6.47890344e-02 -6.14375947e-03  1.31079676e-02 -2.06234306e-02\n",
      "  3.91457751e-02 -1.43456636e-02  2.41084769e-02 -9.00418311e-03\n",
      " -4.04185504e-02  3.76504357e-03  1.58720538e-02 -4.78561670e-02\n",
      "  3.89570817e-02  9.37184878e-03 -2.09052768e-02 -9.52457916e-03\n",
      " -5.64303845e-02  5.39997080e-03 -1.93842072e-02 -5.92039851e-03\n",
      " -7.71399066e-02  3.00424732e-02 -2.99870223e-02 -5.57066165e-02\n",
      " -5.17706610e-02  1.91437732e-02 -4.75102058e-03 -3.52605134e-02\n",
      " -4.03120555e-02  1.81750488e-02  4.68178745e-03 -9.70013347e-03\n",
      " -6.13976084e-02  1.52100716e-02 -4.79541123e-02  2.82628313e-02\n",
      "  6.29597169e-04  2.92768776e-02 -5.12541197e-02  2.08607279e-02\n",
      " -9.82921221e-04  4.06157486e-02 -1.60468947e-02  3.34494673e-02\n",
      "  9.17365700e-02  3.13764960e-02 -4.76469360e-02  1.34068001e-02\n",
      "  8.93217046e-03 -5.23770740e-03 -1.75072215e-02 -1.90831572e-02\n",
      "  7.80545920e-03 -1.37740308e-02  1.76388398e-02 -4.54907566e-02\n",
      " -3.04199499e-03 -1.49666481e-02 -1.38225565e-02 -1.47012379e-02\n",
      "  1.82873458e-02  2.43581156e-03 -2.96357609e-02  1.06290750e-01\n",
      "  1.09214243e-02 -2.86768824e-02  7.21493969e-03  1.32298991e-02\n",
      "  1.04996406e-01  3.18807326e-02  1.93046387e-02 -1.30186114e-03\n",
      "  2.88866516e-02  2.47165319e-02 -1.49600282e-02 -2.43159402e-02\n",
      "  4.68194368e-04 -3.81325781e-02  3.52071831e-03 -2.54429746e-02\n",
      " -2.04058215e-02  6.69222847e-02  1.75038055e-02  2.67624836e-02\n",
      " -1.23880059e-02  6.14894070e-02  3.81182991e-02  1.02366969e-01\n",
      "  3.48290652e-02  1.02825444e-02  5.77649362e-02  1.04014510e-02\n",
      " -1.65662561e-02  1.50017187e-01 -1.09572737e-02  1.75613500e-02\n",
      "  9.12973378e-03  4.64201160e-02  1.40445968e-02  4.01297435e-02\n",
      " -2.01100819e-02 -3.51778604e-02 -3.07632666e-02  4.37712902e-03\n",
      " -1.85927767e-02 -4.80940267e-02 -4.21001948e-02  3.02076731e-02\n",
      " -1.13652507e-02  1.10774245e-02  4.79831779e-03 -3.76085229e-02\n",
      "  2.13810895e-02  9.23061185e-03  1.68875493e-02  4.73686196e-02\n",
      " -8.15519772e-04  4.28285421e-04  6.37877360e-02 -7.86800385e-02\n",
      "  2.30159629e-02  9.40088034e-02  2.32255384e-02 -9.23036691e-03\n",
      " -2.19298303e-02 -6.20472385e-03  2.47134697e-02 -7.18536437e-04\n",
      "  3.69616933e-02 -1.04031321e-02 -6.02050722e-02  1.20765120e-02\n",
      "  2.10564714e-02 -4.50102845e-03 -1.70010887e-02  3.15641277e-02\n",
      " -1.57191302e-03 -6.74917027e-02 -1.68158263e-02  3.35907489e-02\n",
      "  9.34656151e-03  1.60998050e-02 -8.75244848e-03  3.57453823e-02\n",
      "  2.00921297e-02 -2.34822314e-02 -5.38272746e-02  3.97700034e-02\n",
      " -1.48784658e-02 -7.99582973e-02  2.04477236e-02 -8.13127831e-02\n",
      "  3.46938404e-03 -3.15278918e-02  3.46564241e-02 -1.01831974e-02\n",
      "  2.11542640e-02 -4.37077880e-02  6.78847879e-02 -4.12280336e-02\n",
      "  1.01708379e-02  3.41582298e-03 -6.99140597e-03 -5.11761755e-02\n",
      "  4.70781773e-02  8.28228332e-03  9.89443436e-03 -2.08429638e-02\n",
      " -3.27036753e-02  1.93798300e-02  2.85823643e-03 -6.44315546e-03\n",
      "  4.72075529e-02 -1.01529807e-02  3.91608365e-02 -2.42374069e-03\n",
      " -2.30879319e-04 -3.53776403e-02  1.42735774e-02 -6.58446923e-02\n",
      " -4.82351221e-02  4.40492906e-04  1.59350794e-03  8.03527981e-03\n",
      " -2.96181459e-02  2.99189221e-02  3.33177969e-02 -3.97772901e-02\n",
      " -1.12853916e-02 -1.16606727e-02  3.01798824e-02  6.71561807e-02\n",
      " -3.25208902e-02 -4.76766564e-02 -5.28781377e-02 -2.54259836e-02\n",
      " -1.94540508e-02  8.80317986e-02 -2.05146223e-02 -3.26061361e-02\n",
      " -5.42924255e-02  2.67006904e-02  4.11027707e-02 -1.18618617e-02\n",
      "  5.02572879e-02 -1.00236863e-01  1.78996064e-02  2.68662069e-02\n",
      "  6.63227886e-02  8.64136666e-02  1.83440594e-03  5.46944998e-02\n",
      "  1.62635408e-02 -1.04199024e-02 -1.09221470e-02 -2.59527639e-02\n",
      " -3.27698812e-02  5.90132587e-02 -2.03851573e-02 -1.94320660e-02\n",
      " -1.42086390e-02  6.61039874e-02  3.63039821e-02 -2.58171675e-03\n",
      "  3.71294259e-03  4.04091738e-02 -5.11945300e-02 -1.45925693e-02\n",
      " -6.14963286e-02 -5.84112555e-02 -5.48787639e-02  1.05084181e-02\n",
      " -2.07467307e-03 -2.04193983e-02  5.52770123e-02 -2.73887422e-02\n",
      "  2.24909112e-02 -3.31956893e-02 -1.00886384e-02  3.69593762e-02\n",
      "  3.18602473e-02  1.42806703e-02  3.62027921e-02 -1.85108592e-03\n",
      " -3.99925299e-02 -4.09737192e-02 -4.07279376e-03  6.25740737e-02\n",
      "  2.97641344e-02  5.97359939e-03  1.83115415e-02 -2.19819862e-02\n",
      "  1.84231997e-02 -2.09307745e-02 -1.19937574e-02 -2.16218214e-02\n",
      " -1.47394813e-03  3.57533284e-02 -1.92257983e-03 -1.00151449e-03\n",
      " -5.27946688e-02 -1.17637506e-02  3.84691507e-02  3.33542079e-02\n",
      " -3.53918485e-02 -9.37164202e-03 -6.24914169e-02  4.78650481e-02\n",
      "  1.25431214e-02  9.71213542e-03 -4.07328298e-05 -3.30421180e-02\n",
      "  3.20871323e-02  7.46728154e-03 -1.28444778e-02  2.20206529e-02\n",
      " -2.73299050e-02 -2.12146042e-04  1.42066684e-02 -5.29631339e-02\n",
      " -2.26384029e-02  3.39238420e-02  1.06910840e-02 -1.37925185e-02\n",
      " -1.67814121e-02  9.82178599e-02  2.24647243e-02  4.65606572e-03\n",
      "  3.24172787e-02 -1.50712971e-02 -3.27204578e-02  1.37835238e-02\n",
      "  2.40409207e-02 -8.20652768e-02 -8.81500449e-03 -2.36239452e-02\n",
      " -6.41181991e-02  7.90349115e-03  2.05552708e-02 -1.12270424e-02\n",
      " -6.19866252e-02  3.67133841e-02  2.43519973e-02 -7.58571643e-03\n",
      " -6.76395595e-02  1.37958443e-02 -3.05573773e-02  7.55525231e-02\n",
      " -6.77917013e-03  2.95802578e-02 -1.97970048e-02 -1.32748140e-02\n",
      " -6.64578844e-03 -6.07100576e-02 -4.35595252e-02 -5.44196218e-02\n",
      " -6.69376701e-02  3.24571468e-02  3.42530683e-02  8.28986093e-02\n",
      " -5.46508050e-03 -1.28058624e-02  6.41625701e-03 -3.56586948e-02\n",
      " -8.32397956e-03 -7.80941360e-03  8.02235901e-02 -2.78984364e-02\n",
      "  3.21185822e-03  1.56260692e-02  3.57992239e-02 -2.83106249e-02\n",
      " -3.99828516e-02 -1.81357432e-02  8.91435444e-02 -9.12234746e-03\n",
      " -8.44146777e-03  1.19551048e-02  3.47701907e-02 -1.07110851e-02\n",
      "  1.25054717e-02  7.91278407e-02 -2.91311182e-02  9.25887725e-04\n",
      " -5.13378978e-02  2.53818482e-02  3.42532923e-03 -2.26054825e-02\n",
      " -2.37152334e-02 -1.31264785e-02 -1.13563733e-02 -9.47913527e-02\n",
      " -3.13485563e-02  1.63643062e-02  7.88741633e-02  4.22976315e-02\n",
      "  3.55871171e-02  1.56116458e-02 -4.85185646e-02 -4.95551936e-02\n",
      "  6.37193443e-03  2.66989209e-02  9.74233076e-03  1.49998628e-02\n",
      " -4.29319553e-02  3.82339954e-03  1.49082970e-02 -3.38588730e-02\n",
      " -9.08781067e-02 -1.41132576e-02 -6.01203591e-02  1.14498958e-02\n",
      " -1.29104210e-02  3.17574255e-02 -5.43039404e-02  7.54252821e-03\n",
      " -5.36470376e-02  1.79186314e-02  1.20916534e-02 -6.13530800e-02\n",
      " -4.81526740e-03  2.36521289e-02 -3.65912877e-02  3.29771750e-02\n",
      "  4.95151915e-02  2.54757088e-02  1.51087232e-02 -2.33429968e-02\n",
      " -2.31636167e-02  3.05579440e-03 -6.51019812e-02  3.86961028e-02\n",
      " -2.72216704e-02  2.82975007e-02 -1.93656366e-02  3.29206930e-03\n",
      " -7.75238574e-02  4.07097861e-03 -8.52427259e-02 -3.15438099e-02\n",
      " -3.22128646e-02  1.03036333e-02  7.22713815e-03  8.57165977e-02\n",
      " -2.80199144e-02  9.12220869e-03 -1.64207537e-02  1.26548102e-02\n",
      " -2.74429265e-02  3.26904841e-02  3.25857960e-02 -3.32251079e-02\n",
      " -7.14939786e-03  2.23058388e-02 -4.03286926e-02  1.16514768e-02\n",
      " -5.55908978e-02  1.99414715e-02 -7.38891168e-03 -1.11407181e-02\n",
      "  1.74443480e-02  4.89025377e-02 -6.04066141e-02  1.03976270e-02\n",
      " -6.41458258e-02  3.06223705e-02 -2.59308405e-02  6.53706258e-03\n",
      "  7.51307458e-02 -6.25695065e-02  3.68146561e-02  1.10828166e-03\n",
      " -2.13117022e-02  4.69309539e-02  4.42920290e-02 -5.61159737e-02\n",
      "  9.89777781e-03  1.84507146e-02  2.45492849e-02 -3.66838686e-02\n",
      " -8.93442035e-02  4.20565642e-02 -9.41530708e-03 -5.94416773e-03\n",
      " -7.76726753e-02  9.41704307e-03 -1.15737962e-02 -2.66601238e-02\n",
      "  1.61197055e-02  4.88019027e-02 -2.41944473e-02  1.56395510e-02\n",
      "  1.57477595e-02 -7.24175423e-02  1.24241011e-02  2.75379587e-02\n",
      " -1.26544498e-02 -6.88805729e-02 -3.31361103e-03  3.58403698e-02\n",
      "  3.80484574e-02 -5.04233614e-02 -1.04254186e-02  3.72406915e-02\n",
      " -1.39091676e-02 -2.67959647e-02  2.80827843e-02 -5.87977683e-33\n",
      " -5.87035790e-02 -4.41760570e-02 -6.67560985e-03  4.28526066e-02\n",
      " -1.56059545e-02 -1.11404816e-02 -2.76296437e-02  3.41783017e-02\n",
      "  1.87253784e-02  5.30519597e-02  2.04266440e-02  2.21682321e-02\n",
      "  2.18513943e-02  7.25043984e-03  1.25915036e-02 -2.20231200e-03\n",
      "  4.66261469e-02 -2.78353803e-02 -1.33587169e-02 -2.83440556e-02\n",
      " -2.15879665e-03  2.76704822e-02  3.12443189e-02  7.20121106e-03\n",
      " -1.47268390e-02  1.75893828e-02 -8.84154160e-03 -2.03347579e-02\n",
      "  2.23629400e-02  3.49115171e-02 -2.89848521e-02  9.52439941e-03\n",
      "  5.74067840e-03 -3.10436934e-02 -2.78358757e-02  8.65894184e-02\n",
      " -2.23085135e-02 -4.13132980e-02  2.49187760e-02  1.37355477e-02\n",
      " -6.30218834e-02 -6.21832199e-02  1.05506554e-02 -4.39173579e-02\n",
      "  2.59134267e-02 -1.49439573e-02  5.01573272e-02 -5.29151456e-03\n",
      " -8.96840263e-03 -1.58035737e-02 -1.32654086e-01  9.44091473e-03\n",
      "  2.72251740e-02  7.38317221e-02  9.36548784e-02 -1.14751384e-02\n",
      "  9.21468891e-05 -2.12900173e-02 -1.19619351e-02 -9.70028806e-03\n",
      " -3.77229564e-02  1.18676081e-01 -2.71390635e-03 -2.25421228e-02\n",
      " -1.96175519e-02  6.54845163e-02 -1.27537074e-02 -3.00802235e-02\n",
      " -2.17788015e-02  4.57525700e-02  4.27389331e-02  3.57106291e-02\n",
      "  3.04552596e-02  6.76773563e-02  4.67266748e-03 -2.78628729e-02\n",
      " -1.98922977e-02 -2.44254526e-02  2.11821459e-02 -1.39648365e-02\n",
      "  2.71946415e-02  1.07067684e-02  2.08743569e-02 -4.33002524e-02\n",
      " -3.25998440e-02 -3.38886678e-02 -1.00772409e-02  5.13888150e-03\n",
      "  2.70847380e-02  3.34694539e-03 -3.96686271e-02  6.02214318e-03\n",
      "  3.61952861e-03 -3.40046287e-02  1.13880020e-02  1.94685571e-02\n",
      " -3.62794101e-02  4.18051369e-02 -3.51225701e-03  2.33137906e-02\n",
      " -5.77425212e-02 -2.83003002e-02 -3.94053645e-02  4.50800313e-03\n",
      "  3.00609004e-02  1.56663731e-03  1.57702174e-02 -1.30955139e-02\n",
      " -8.41453075e-02 -1.27224084e-02  5.28620603e-03 -3.17458585e-02\n",
      " -5.63582988e-04 -3.59095708e-02 -6.38643373e-03  2.24118261e-03\n",
      "  1.43475002e-02  1.95049327e-02  1.27216056e-02 -1.96006671e-02\n",
      " -3.04543227e-02  3.87765765e-02  1.11298785e-02  5.68714440e-02\n",
      " -4.99775782e-02  1.13472156e-02 -4.61825766e-02  2.96097677e-02\n",
      "  6.48488030e-02 -7.73568973e-02  3.17661883e-03  2.65018214e-02\n",
      "  2.11958735e-07  9.20253061e-03  6.50739223e-02  3.92202698e-02\n",
      "  3.15275714e-02  2.73719113e-02  1.63668804e-02  2.11351123e-02\n",
      "  2.73391269e-02  3.76802385e-02 -4.91521098e-02  1.28191561e-02\n",
      " -2.21797917e-03  2.25550290e-02  4.37164418e-02 -1.20575562e-01\n",
      " -1.29169943e-02 -4.05381732e-02 -2.69593066e-03 -4.07128446e-02\n",
      " -2.16768142e-02  5.90961911e-02  8.61828774e-02  6.24304218e-03\n",
      "  1.94169302e-02 -1.66524258e-02 -5.05796149e-02  2.07997225e-02\n",
      "  3.54102515e-02  1.02847656e-02  1.14982547e-02 -2.78967842e-02\n",
      " -3.15037780e-02  9.71595664e-03  6.26343563e-02 -3.92104164e-02\n",
      "  2.71396507e-02  2.34822333e-02  3.54978926e-02  4.38936893e-03\n",
      "  1.87108815e-02 -8.74913484e-03 -2.17951741e-03 -3.26743685e-02\n",
      " -1.37409568e-02  3.07036042e-02 -6.29911348e-02 -1.86327863e-02\n",
      " -4.29739058e-02  3.62911448e-02 -1.01089608e-02  1.47918500e-02\n",
      "  5.87928109e-03  2.68226536e-03  1.39363343e-02  1.62570514e-02\n",
      " -3.93654369e-02  1.66051947e-02 -4.29221280e-02 -2.60678437e-02\n",
      "  1.84550090e-03 -3.84776480e-02 -2.48537418e-02 -2.05987282e-02\n",
      " -1.27643980e-02  6.19879253e-02  1.08021516e-02 -1.40246353e-03\n",
      "  1.50765186e-34  1.73288584e-02  1.15484511e-02  3.83888148e-02\n",
      "  2.22917143e-02  2.83790007e-02 -1.83677580e-02 -5.93299093e-03\n",
      "  1.70431845e-02  3.46785337e-02 -5.01236580e-02 -2.88337376e-02]\n",
      "\n",
      "Sentence: This is a digital humanities project.\n",
      "Embedding: [ 2.27301307e-02  4.39540520e-02 -2.85951570e-02  2.85146944e-03\n",
      " -6.48938045e-02 -4.16972995e-04  3.14743891e-02 -1.29235405e-02\n",
      " -3.91375981e-02 -7.88320228e-03  1.03285946e-01 -1.40022691e-02\n",
      "  2.59795487e-02 -1.45827364e-02 -1.67545155e-02 -5.16031235e-02\n",
      " -1.72193942e-03  1.38949212e-02 -4.31380533e-02 -2.53415070e-02\n",
      " -3.76990624e-02  5.84664568e-02 -4.85113189e-02 -1.42877102e-02\n",
      " -1.87198482e-02 -1.56615321e-02 -7.98707157e-02  4.58924994e-02\n",
      " -1.63319688e-02 -4.02938165e-02 -1.96767654e-02 -2.07600668e-02\n",
      "  9.24730022e-03  2.77403984e-02  1.36672838e-06 -1.60131194e-02\n",
      "  2.95097777e-03 -2.50246245e-02  1.27513641e-02  2.84169409e-02\n",
      "  9.74965096e-02  4.05680314e-02 -4.24564108e-02 -3.76235764e-03\n",
      "  2.55592503e-02 -2.47385986e-02  1.31571189e-01  6.52739732e-03\n",
      "  1.53501295e-02  2.85593346e-02  8.85952637e-03 -4.07180116e-02\n",
      " -1.57752242e-02 -4.69680801e-02 -1.78561509e-02  6.24733791e-02\n",
      " -3.36038359e-02  6.99384958e-02  2.58240309e-02  3.39955948e-02\n",
      "  6.88182376e-03  5.41860871e-02 -2.97597442e-02 -2.58649420e-02\n",
      " -6.98921606e-02 -3.97759117e-02  6.69970829e-03 -7.92901739e-02\n",
      "  1.74226072e-02  3.40847485e-02  7.72893801e-02 -4.04321849e-02\n",
      "  3.15548033e-02  3.69381532e-02 -1.64351091e-02  6.22266717e-02\n",
      " -6.20272085e-02  2.91038342e-02 -1.08594634e-02  2.59071514e-02\n",
      " -2.44826712e-02 -2.76831836e-02 -1.74556915e-02  1.44210868e-02\n",
      "  5.52395023e-02  2.41204947e-02  3.82552408e-02  2.77140271e-02\n",
      " -3.15588042e-02 -7.92626143e-02  5.28386906e-02  7.48084206e-03\n",
      "  2.68059596e-02  3.53638157e-02  6.22122660e-02  4.71601821e-03\n",
      " -4.29318771e-02 -3.29757929e-02  2.07655951e-02  3.58247198e-02\n",
      "  3.06715835e-02  6.67985110e-03 -1.96229015e-02  6.20086193e-02\n",
      "  4.35834825e-02 -2.03707386e-02 -1.04898214e-02 -5.71216363e-03\n",
      "  3.82846147e-02  4.52290438e-02 -1.96093880e-02  3.93249933e-03\n",
      " -1.58444531e-02 -4.11093496e-02 -1.62490029e-02 -3.20508480e-02\n",
      "  4.99375165e-03 -2.44240742e-02  3.23881693e-02  1.42308259e-02\n",
      "  4.54765432e-05  4.21533138e-02 -1.16419150e-02  8.13728105e-03\n",
      " -1.09774126e-02  7.49524310e-02 -3.92774232e-02  3.55280424e-03\n",
      " -1.05038295e-02 -1.41281923e-02  2.26091053e-02  1.09666679e-02\n",
      "  5.99260293e-02 -3.07455454e-02  3.09506394e-02 -2.63585355e-02\n",
      "  4.13306653e-02 -2.93604098e-02 -5.98409027e-02  2.34370138e-02\n",
      "  4.55890223e-02 -1.80017184e-02  5.67918643e-02  1.62866823e-02\n",
      " -7.88839970e-05 -2.05236636e-02  5.77042364e-02 -4.78852168e-02\n",
      " -5.48648555e-03 -2.35725613e-03 -8.79283994e-03  5.59340045e-02\n",
      " -2.94502173e-02 -1.06079597e-02  3.47299166e-02 -1.01474021e-02\n",
      " -1.36093143e-02  3.05034984e-02  5.53487241e-03  6.60906918e-03\n",
      "  3.59128751e-02  1.30742583e-02 -1.16717480e-02  1.04949076e-03\n",
      " -1.24090342e-02 -2.65752804e-02  1.70254465e-02 -1.12669617e-02\n",
      " -2.56526861e-02  1.96118723e-03  7.88215827e-03  7.67572522e-02\n",
      " -5.05654747e-03  2.66792979e-02  3.90593633e-02  8.13486278e-02\n",
      "  2.75299828e-02 -4.59654704e-02 -3.90506256e-03  2.76741423e-02\n",
      "  4.80108634e-02 -9.93853509e-02 -3.49617749e-02  5.88721149e-02\n",
      "  1.03252329e-01  1.27751678e-02 -2.57537905e-02  3.21095698e-02\n",
      " -2.68080216e-02 -7.17540458e-03 -3.62419859e-02 -2.01377980e-02\n",
      "  4.89994772e-02  1.19234715e-02  4.80318256e-03 -1.23620359e-02\n",
      "  7.70558743e-03 -4.31663953e-02  2.03746231e-03 -4.22480851e-02\n",
      "  1.42428530e-02  8.48655961e-03  5.17210970e-03  1.11641295e-01\n",
      "  5.52300811e-02 -3.91876735e-02  9.53323022e-02 -1.62928160e-02\n",
      " -5.52692264e-03  3.04886214e-02  1.37452437e-02 -1.04013123e-02\n",
      " -1.53489979e-02 -8.36661458e-03  2.62239482e-02 -1.48684103e-02\n",
      "  1.94544287e-03 -8.70986935e-03  3.86310928e-02  1.12954237e-01\n",
      " -5.07965125e-03 -3.11552789e-02 -4.44225734e-03 -4.52050335e-05\n",
      " -4.38854302e-04 -3.77688780e-02 -6.65767398e-03  1.36444625e-02\n",
      "  1.10206192e-05  5.53023852e-02 -4.54841778e-02  1.16629712e-02\n",
      "  1.77309886e-02  3.45433727e-02 -3.44881788e-02  3.01489644e-02\n",
      "  6.16983958e-02  4.50480767e-02  4.11398709e-02 -1.33079708e-01\n",
      "  1.43545084e-02  1.42766060e-02  3.39553207e-02  4.39296775e-02\n",
      "  1.87216997e-02 -5.94183058e-02  6.69110641e-02  5.54917753e-03\n",
      "  2.39724349e-02  2.34049857e-02  7.85531290e-03 -2.13875007e-02\n",
      "  1.42271137e-02  9.69399139e-03  3.54848430e-02  3.73592600e-02\n",
      " -5.57542294e-02 -3.70592438e-02 -2.24675015e-02 -7.98003469e-03\n",
      "  2.16141008e-02 -5.83728962e-02  3.97649445e-02 -4.94243763e-02\n",
      " -3.44514996e-02 -1.48717696e-02  3.97282839e-02 -2.38897577e-02\n",
      " -8.42633694e-02 -4.07883674e-02 -1.74184814e-02 -3.89238633e-02\n",
      " -4.13806960e-02 -2.01138258e-02  7.83294090e-04  1.85101889e-02\n",
      " -2.35919543e-02 -4.77711298e-02  4.16758610e-03 -4.17137239e-03\n",
      " -4.06404883e-02 -5.86793153e-03 -5.51811866e-02 -1.51252728e-02\n",
      "  1.77409165e-02 -1.57306287e-02  3.03247906e-02 -5.84744215e-02\n",
      " -7.66032562e-03  2.92400792e-02  3.46911438e-02  2.46671174e-04\n",
      "  3.82672213e-02  9.08130314e-03  1.33191794e-02 -1.41587360e-02\n",
      "  9.22819879e-03 -1.36563797e-02 -4.12883759e-02  6.78415596e-02\n",
      "  1.31380954e-03 -6.06127009e-02  2.24933531e-02  3.12957726e-02\n",
      " -2.08354276e-02  6.48570284e-02  4.68819514e-02 -8.46114233e-02\n",
      "  6.28913846e-03 -6.18030056e-02  2.99440906e-03  1.38141066e-02\n",
      "  1.52095631e-02 -8.13520607e-03 -1.91641152e-02 -7.23383913e-04\n",
      "  2.31266990e-02 -2.40683295e-02 -2.10171938e-02  5.38933352e-02\n",
      "  1.24385916e-02  2.25342643e-02 -2.54518930e-02 -2.97950245e-02\n",
      "  2.37693824e-02  1.57876220e-02  9.40930750e-03 -1.11371418e-02\n",
      "  8.24979991e-02 -2.54536234e-02  1.23270229e-02  1.40960170e-02\n",
      " -1.27110891e-02  5.30427769e-02  5.09557351e-02  1.25911683e-01\n",
      " -3.55136059e-02 -7.30659887e-02  1.94670241e-02 -6.00908734e-02\n",
      " -2.06717849e-02  4.66205999e-02  3.23978774e-02  8.39925429e-04\n",
      "  2.16759592e-02 -6.75808042e-02  2.20152717e-02  1.58526208e-02\n",
      " -5.37734739e-02  1.05245486e-02  1.15841907e-02  4.04038541e-02\n",
      "  1.14229070e-02  1.55180274e-02  2.62393360e-03  5.77929541e-02\n",
      " -2.20889822e-02  9.36628901e-04 -3.88415530e-02  3.16647850e-02\n",
      " -4.94812466e-02 -1.96695067e-02 -3.82800680e-03 -1.06343171e-02\n",
      "  5.95747121e-03 -4.67128772e-03  5.09645082e-02  4.87503945e-04\n",
      " -2.22451240e-02  1.57233961e-02  2.64413320e-02  3.31217907e-02\n",
      "  3.44448052e-02  5.62645029e-03  1.89224444e-02 -2.66098324e-02\n",
      " -1.04886405e-02 -4.14968729e-02 -5.65936491e-02  2.01899167e-02\n",
      " -3.53837796e-02 -2.19162162e-02  2.69971509e-02  1.62994885e-03\n",
      " -2.34015118e-02  2.48232801e-02 -1.84661243e-02 -1.26619646e-02\n",
      " -6.03429507e-03 -2.64429450e-02  3.26472078e-03  2.27009226e-03\n",
      "  8.21253937e-03 -3.89127880e-02 -1.58952437e-02 -1.39829414e-02\n",
      " -2.93075629e-02 -5.63684851e-02 -2.49280427e-02  1.39325205e-03\n",
      "  6.34449860e-03 -4.53456827e-02  3.60053917e-03 -4.44493219e-02\n",
      " -2.09609736e-02  7.00366218e-03  3.54684554e-02  3.74863520e-02\n",
      " -3.33099551e-02 -4.95460518e-02 -1.61273573e-02  1.36252260e-02\n",
      "  1.40362391e-02  4.83117579e-03  2.04029176e-02 -1.51813291e-02\n",
      " -1.30330538e-02  1.18048154e-02  2.80239843e-02  3.22888717e-02\n",
      " -6.96818382e-02 -9.46856663e-03 -4.66676764e-02 -1.82974674e-02\n",
      "  4.75038365e-02 -4.19676006e-02 -2.69432310e-02  4.29278053e-02\n",
      " -6.36886479e-03  1.62674896e-02 -1.88254099e-02 -1.60175674e-02\n",
      " -1.12527581e-02  3.35179567e-02 -2.89995093e-02 -7.29342028e-02\n",
      "  2.50155875e-03 -6.68983348e-03 -4.81333993e-02 -1.35062980e-02\n",
      "  2.49247178e-02 -6.55959100e-02  4.56851870e-02  5.19878566e-02\n",
      " -3.85555737e-02  4.07509506e-02  2.64289584e-02 -1.15996093e-01\n",
      "  1.03157153e-02  6.39190245e-03 -1.61020607e-02  9.60675813e-03\n",
      " -5.63180819e-02 -2.33751070e-02  1.85800213e-02  2.87932679e-02\n",
      " -2.55277064e-02 -7.61334226e-02 -6.41897367e-03  3.76100764e-02\n",
      "  1.14310188e-02  3.18048671e-02 -7.92888030e-02  3.40700485e-02\n",
      " -3.16525884e-02  1.01893721e-02 -9.14785359e-03  2.74470523e-02\n",
      " -5.41063286e-02 -2.07733680e-02 -4.11565453e-02 -2.37585697e-02\n",
      " -2.00915318e-02  4.67479089e-03  1.20612606e-03  4.65676747e-03\n",
      " -3.41206267e-02  1.89437363e-02  5.35175065e-03 -2.64062192e-02\n",
      " -2.51839813e-02 -2.97346357e-02 -7.00946078e-02 -1.68202035e-02\n",
      "  1.34527208e-02  7.19868671e-03 -2.02734899e-02 -1.30732998e-03\n",
      "  5.92489131e-02 -9.36241262e-03 -4.09125648e-02 -4.66741771e-02\n",
      "  1.84325539e-02  3.95881794e-02  6.30480349e-02  3.07608712e-02\n",
      " -1.87313743e-02  3.45949903e-02  2.96065062e-02 -7.13810697e-03\n",
      " -3.51002663e-02  8.34648847e-04 -2.74226442e-03  2.37587318e-02\n",
      " -9.97170359e-02  1.40959751e-02  3.07248887e-02  3.51861306e-02\n",
      " -1.41177876e-02  6.36408404e-02  2.11198460e-02 -1.07577657e-02\n",
      "  1.03001446e-04  7.95629248e-03 -2.81009544e-02 -7.64837069e-03\n",
      "  9.47918594e-02  9.35438648e-03  3.66220325e-02  1.94505695e-02\n",
      " -2.05605198e-02  8.44662450e-03  5.74604385e-02 -1.65732279e-02\n",
      " -3.79479234e-03 -3.96914594e-02  3.28846164e-02  2.41350159e-02\n",
      "  1.29802683e-02 -1.96193829e-02 -5.41803762e-02 -3.91937345e-02\n",
      "  2.85529811e-02  6.58678114e-02 -2.31967214e-03  1.20683694e-02\n",
      " -1.13848839e-02  1.60488710e-02  1.80625003e-02 -3.18072326e-02\n",
      "  3.19817774e-02 -4.46583033e-02  2.42256522e-02  2.02701241e-02\n",
      " -2.58963201e-02 -1.97929498e-02  2.23162863e-02  1.73776988e-02\n",
      "  2.09897030e-02 -9.96641465e-04 -1.84107125e-02  1.45054599e-02\n",
      " -1.02233991e-01 -4.84442571e-03 -8.22268147e-03 -5.59212050e-33\n",
      "  4.25640633e-03 -5.38781323e-02  2.23654881e-02  1.40084578e-02\n",
      " -7.19940988e-03 -4.25492339e-02 -2.91931294e-02  3.19916056e-03\n",
      " -4.67328206e-02  1.63114518e-02 -6.45358488e-02 -2.30690483e-02\n",
      "  3.23830247e-02 -1.63903609e-02  1.71931926e-02  2.24791411e-02\n",
      "  8.78702756e-03  1.52973868e-02 -3.72456051e-02  1.07030151e-03\n",
      " -1.01256827e-02 -6.08033389e-02  3.15946736e-03  1.42461527e-02\n",
      "  5.19814342e-02  9.74044390e-03 -8.02996829e-02 -5.58503903e-02\n",
      "  2.22513601e-02  3.22815813e-02 -2.25934032e-02 -5.27357012e-02\n",
      "  4.99483990e-03 -2.19009537e-02  3.50504741e-02  5.33797555e-02\n",
      " -5.54623529e-02  1.85220577e-02  2.18928196e-02  4.15282398e-02\n",
      "  6.17872700e-02 -5.72764613e-02  1.04381153e-02 -1.44529147e-02\n",
      "  2.15600157e-04 -7.67425029e-03 -2.72468384e-02  1.47130778e-02\n",
      " -4.38613445e-02 -6.33995906e-02 -4.30437438e-02 -1.56067573e-02\n",
      " -3.41030844e-02  4.74001020e-02  3.84540632e-02 -4.85087745e-02\n",
      " -7.22929556e-03 -2.45149783e-03 -2.80770715e-02  5.35277799e-02\n",
      "  1.02094412e-02  6.82135986e-04  4.18372080e-02 -6.23930395e-02\n",
      " -1.95112862e-02  2.34560966e-02 -4.22940496e-03 -1.65038891e-02\n",
      " -6.79626223e-03  1.10095805e-02 -9.03500244e-03  7.95923322e-02\n",
      "  3.75003479e-02  9.56206545e-02 -1.25024496e-02 -2.66136695e-03\n",
      "  3.76752391e-02 -1.37735596e-02  9.57513694e-03  1.89108786e-03\n",
      "  8.60206317e-03 -2.65021268e-02  2.83885635e-02  9.89673007e-03\n",
      "  7.31444015e-05 -3.25418934e-02  1.46524301e-02  7.15681445e-03\n",
      "  5.11480821e-03  2.08738465e-02  4.68344521e-03  1.41040003e-02\n",
      "  9.48607776e-05 -3.78891500e-03 -3.03324801e-03  4.38846499e-02\n",
      "  4.56466665e-03  7.07758442e-02 -2.20474601e-03 -6.75138459e-02\n",
      " -1.32227372e-02 -4.52933349e-02 -2.83842515e-02  3.96585613e-02\n",
      "  4.75130565e-02 -3.27672027e-02 -1.95093434e-02  2.68112533e-02\n",
      " -6.21315949e-02  1.75415929e-02  3.89816798e-02  2.70121801e-03\n",
      " -1.92832313e-02 -3.85175943e-02  1.97246820e-02 -1.01272352e-02\n",
      "  2.38880143e-02 -2.40571368e-02  1.63671747e-02 -1.62647404e-02\n",
      "  4.52475958e-02 -3.06424033e-02 -2.10548267e-02 -1.35818738e-02\n",
      "  1.71953961e-02  2.26784265e-03  8.90764594e-03  1.10800250e-03\n",
      "  1.29498739e-03 -1.24440547e-02 -1.53360320e-02 -1.28613636e-02\n",
      "  1.99573208e-07  2.14635171e-02  4.49124835e-02  4.82525826e-02\n",
      "  9.21950042e-02  1.86356492e-02 -3.83951515e-02  2.29675230e-03\n",
      "  8.78744572e-03 -4.42392342e-02 -5.73818153e-03  3.81520689e-02\n",
      "  7.28612114e-03  1.90177523e-02  6.90237135e-02 -1.07362516e-01\n",
      " -4.45943065e-02 -5.24678268e-02 -5.05115092e-02  1.77261606e-02\n",
      " -4.13338514e-03  5.34666553e-02  5.26689067e-02  2.99485922e-02\n",
      " -1.37030082e-02 -2.43501272e-02  2.03163363e-02 -2.51719705e-03\n",
      "  1.46142421e-02  1.28922975e-02 -3.84557135e-02 -6.73534051e-02\n",
      " -3.88084389e-02 -1.11010270e-02 -4.13892679e-02  6.73779193e-03\n",
      " -4.38698716e-02 -1.89362317e-02 -1.45635307e-02  1.93193171e-03\n",
      "  2.04955582e-02 -2.28642039e-02  2.78844358e-03 -1.66684985e-02\n",
      "  4.16228026e-02  4.50088680e-02  1.16040654e-01  3.48850228e-02\n",
      "  3.38645652e-02 -2.43284199e-02 -5.27737290e-03  4.38812897e-02\n",
      " -4.38747294e-02  2.30272934e-02 -3.78858298e-02  1.70614403e-02\n",
      " -5.13360240e-02 -6.47965213e-03 -4.57822606e-02  4.30658832e-02\n",
      " -6.09221198e-02  1.32956542e-02 -1.54709816e-02  2.22588051e-02\n",
      "  1.41301111e-03  5.42919966e-04  1.04258573e-02 -1.75873321e-02\n",
      "  8.23785178e-35  2.96419039e-02 -6.13461845e-02 -2.35984605e-02\n",
      " -4.60460456e-03 -2.36235838e-02 -3.47858407e-02 -1.48401386e-03\n",
      " -4.28942740e-02 -6.11785315e-02  3.54436487e-02 -4.41999873e-03]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    model_name_or_path=\"all-mpnet-base-v2\", device=\"cpu\"\n",
    ")  # Set device to \"cpu\" or \"cuda\" depending on available hardware and speed\n",
    "\n",
    "\n",
    "# Create the list of sentences\n",
    "sentences = [\n",
    "    \"The Sentence Transformer library provides an easy way to create embeddings.\",\n",
    "    \"Sentence embedding is part of the process.\",\n",
    "    \"This is a digital humanities project.\",\n",
    "]\n",
    "\n",
    "# encode sentences by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embedding_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# check the embeddings\n",
    "for sentence, embedding in embedding_dict.items():\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding: {embedding}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b220bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d63a2fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for CPU embedding creation: 5.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Move the model to the CPU for embedding creation\n",
    "embedding_model.to(\"cpu\")\n",
    "\n",
    "# Generate embeddings for each chunk on the CPU\n",
    "# This iterates over each item in pages_and_chunks_over_min_token_len\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Time taken for CPU embedding creation: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Optional: Move the model to the GPU for faster embedding creation\n",
    "# Uncomment the following lines if a GPU is available for use with \"cuda\"\n",
    "\n",
    "# embedding_model.to(\"cuda\")  # Requires a GPU to be installed\n",
    "\n",
    "# # Start timing for GPU embedding\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Create embeddings on the GPU (if available)\n",
    "# for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "#     item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])\n",
    "\n",
    "# # Calculate and print the elapsed time for GPU processing\n",
    "# elapsed_time = time.time() - start_time\n",
    "# print(f\"Time taken for GPU embedding creation: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f4938a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Measure execution time for batch embedding and saving (if in Jupyter, uncomment %%time)\n",
    "# %%time\n",
    "\n",
    "# Embed all text chunks in batches to optimize memory and performance\n",
    "# Uncomment the following to batch embeddings:\n",
    "# text_chunk_embeddings = embedding_model.encode(\n",
    "#     text_chunks,  # List of text chunks to embed\n",
    "#     batch_size=32,  # Adjust batch size as needed to improve speed and memory efficiency\n",
    "#     convert_to_tensor=True  # Optional: return embeddings as PyTorch tensor for further tensor operations\n",
    "# )\n",
    "\n",
    "# Optional: Display or use `text_chunk_embeddings` for further processing\n",
    "\n",
    "# Save the text chunks and embeddings to a DataFrame\n",
    "# Note: Adjust path as needed\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(\n",
    "    embeddings_df_save_path, index=False\n",
    ")  # Save DataFrame as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4de16ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 55 The author ...</td>\n",
       "      <td>1204</td>\n",
       "      <td>194</td>\n",
       "      <td>301.00</td>\n",
       "      <td>[ 1.79897361e-02  3.91299501e-02 -4.22144756e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5</td>\n",
       "      <td>Under the earlier appellation, John Unsworth h...</td>\n",
       "      <td>1587</td>\n",
       "      <td>235</td>\n",
       "      <td>396.75</td>\n",
       "      <td>[ 4.28221188e-02  3.57256345e-02 -4.90087867e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5</td>\n",
       "      <td>Crucially, there are digital humanities center...</td>\n",
       "      <td>845</td>\n",
       "      <td>129</td>\n",
       "      <td>211.25</td>\n",
       "      <td>[ 2.03686710e-02  3.22138183e-02 -2.67556552e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...</td>\n",
       "      <td>1471</td>\n",
       "      <td>228</td>\n",
       "      <td>367.75</td>\n",
       "      <td>[ 2.54732836e-02  2.58226339e-02 -3.68595086e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>We could attempt to refine this “outlook” quan...</td>\n",
       "      <td>2263</td>\n",
       "      <td>349</td>\n",
       "      <td>565.75</td>\n",
       "      <td>[ 4.28117551e-02  4.96095791e-02 -1.71628781e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0           -5  ADE Bulletin ◆ Number 150, 2010 55 The author ...   \n",
       "1           -5  Under the earlier appellation, John Unsworth h...   \n",
       "2           -5  Crucially, there are digital humanities center...   \n",
       "3           -4  ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...   \n",
       "4           -4  We could attempt to refine this “outlook” quan...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0              1204               194             301.00   \n",
       "1              1587               235             396.75   \n",
       "2               845               129             211.25   \n",
       "3              1471               228             367.75   \n",
       "4              2263               349             565.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 1.79897361e-02  3.91299501e-02 -4.22144756e-...  \n",
       "1  [ 4.28221188e-02  3.57256345e-02 -4.90087867e-...  \n",
       "2  [ 2.03686710e-02  3.22138183e-02 -2.67556552e-...  \n",
       "3  [ 2.54732836e-02  2.58226339e-02 -3.68595086e-...  \n",
       "4  [ 4.28117551e-02  4.96095791e-02 -1.71628781e-...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713f977",
   "metadata": {},
   "source": [
    "### Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "264ebf03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\n",
    "    \"embedding\"\n",
    "].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(\n",
    "    np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32\n",
    ").to(device)\n",
    "embeddings.shape\n",
    "embeddings.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c14e83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 55 The author ...</td>\n",
       "      <td>1204</td>\n",
       "      <td>194</td>\n",
       "      <td>301.00</td>\n",
       "      <td>[0.0179897361, 0.0391299501, -0.0422144756, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5</td>\n",
       "      <td>Under the earlier appellation, John Unsworth h...</td>\n",
       "      <td>1587</td>\n",
       "      <td>235</td>\n",
       "      <td>396.75</td>\n",
       "      <td>[0.0428221188, 0.0357256345, -0.0490087867, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5</td>\n",
       "      <td>Crucially, there are digital humanities center...</td>\n",
       "      <td>845</td>\n",
       "      <td>129</td>\n",
       "      <td>211.25</td>\n",
       "      <td>[0.020368671, 0.0322138183, -0.0267556552, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4</td>\n",
       "      <td>ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...</td>\n",
       "      <td>1471</td>\n",
       "      <td>228</td>\n",
       "      <td>367.75</td>\n",
       "      <td>[0.0254732836, 0.0258226339, -0.0368595086, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4</td>\n",
       "      <td>We could attempt to refine this “outlook” quan...</td>\n",
       "      <td>2263</td>\n",
       "      <td>349</td>\n",
       "      <td>565.75</td>\n",
       "      <td>[0.0428117551, 0.0496095791, -0.0171628781, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0           -5  ADE Bulletin ◆ Number 150, 2010 55 The author ...   \n",
       "1           -5  Under the earlier appellation, John Unsworth h...   \n",
       "2           -5  Crucially, there are digital humanities center...   \n",
       "3           -4  ADE Bulletin ◆ Number 150, 2010 56 What Is Dig...   \n",
       "4           -4  We could attempt to refine this “outlook” quan...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0              1204               194             301.00   \n",
       "1              1587               235             396.75   \n",
       "2               845               129             211.25   \n",
       "3              1471               228             367.75   \n",
       "4              2263               349             565.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0179897361, 0.0391299501, -0.0422144756, -0...  \n",
       "1  [0.0428221188, 0.0357256345, -0.0490087867, 0....  \n",
       "2  [0.020368671, 0.0322138183, -0.0267556552, 0.0...  \n",
       "3  [0.0254732836, 0.0258226339, -0.0368595086, -0...  \n",
       "4  [0.0428117551, 0.0496095791, -0.0171628781, -0...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0fdf425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [0.0179897361, 0.0391299501, -0.0422144756, -0...\n",
       "1     [0.0428221188, 0.0357256345, -0.0490087867, 0....\n",
       "2     [0.020368671, 0.0322138183, -0.0267556552, 0.0...\n",
       "3     [0.0254732836, 0.0258226339, -0.0368595086, -0...\n",
       "4     [0.0428117551, 0.0496095791, -0.0171628781, -0...\n",
       "5     [0.0407331511, 0.0463119335, -0.0121963033, -0...\n",
       "6     [0.0357671082, 0.0379991904, -0.0240194853, -0...\n",
       "7     [0.0288532246, 0.0799177364, -0.0226198602, -0...\n",
       "8     [0.0360140726, 0.0506579988, -0.0104648927, -0...\n",
       "9     [0.0773864239, 0.0159307439, -0.0220139213, -0...\n",
       "10    [0.0680856034, 0.0339299589, -0.0140206954, -0...\n",
       "11    [0.0413060784, 0.0123664839, 0.00236883759, -0...\n",
       "12    [0.0459209159, 0.0191587787, -0.0439116918, -0...\n",
       "13    [0.0413302518, 0.0325960033, -0.00894801784, -...\n",
       "14    [0.018890053, 0.0348874405, -0.0441482589, -0....\n",
       "Name: embedding, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df6aaf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01798974,  0.03912995, -0.04221448, ...,  0.03801661,\n",
       "         0.01319847, -0.04493817],\n",
       "       [ 0.04282212,  0.03572563, -0.04900879, ...,  0.03242273,\n",
       "         0.02076461, -0.01721456],\n",
       "       [ 0.02036867,  0.03221382, -0.02675566, ...,  0.02016196,\n",
       "         0.01865645, -0.01403168],\n",
       "       ...,\n",
       "       [ 0.04592092,  0.01915878, -0.04391169, ...,  0.01148756,\n",
       "        -0.01844093, -0.0394499 ],\n",
       "       [ 0.04133025,  0.032596  , -0.00894802, ..., -0.00340151,\n",
       "         0.03831667, -0.0250778 ],\n",
       "       [ 0.01889005,  0.03488744, -0.04414826, ...,  0.00217194,\n",
       "         0.03867229, -0.04262922]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.stack(text_chunks_and_embedding_df[\"embedding\"].tolist(), axis=0)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb1d072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaacfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\n",
    "    model_name_or_path=\"all-mpnet-base-v2\", device=device\n",
    ")  # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cbdf0",
   "metadata": {},
   "source": [
    "### Steps for Querying with Embeddings\n",
    "\n",
    "1. **Define a Query String**: Start by creating a query as a text string that represents what you’re searching for.\n",
    "\n",
    "2. **Convert the Query to an Embedding**: Use the same embedding model to transform the query string into an embedding, similar to how the text chunks were embedded.\n",
    "\n",
    "3. **Calculate Similarity**: Perform a similarity comparison (e.g., dot product or cosine similarity) between the query embedding and each text embedding in the dataset.\n",
    "\n",
    "4. **Sort Results by Relevance**: Sort the similarity scores in descending order to identify the most relevant results for your query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cdb9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: digital humanities\n",
      "Time taken to get scores on 15 embeddings: 0.00015 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.8262, 0.8018, 0.7910, 0.7887, 0.7742]),\n",
       "indices=tensor([ 3, 14,  1,  4,  2]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "# 1. Define the query\n",
    "query = \"digital humanities\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples\n",
    "# Ensure that both query_embedding and embeddings are in the same format and dtype\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Convert embeddings to a PyTorch tensor if it's currently a NumPy array\n",
    "if isinstance(embeddings, np.ndarray):\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "# 3. Get similarity scores with the dot product\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(\n",
    "    f\"Time taken to get scores on {len(embeddings)} embeddings: {end_time - start_time:.5f} seconds.\"\n",
    ")\n",
    "\n",
    "# 4. Get the top-k results (keeping this to 5 for now)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fd3247a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': -5,\n",
       " 'sentence_chunk': 'Crucially, there are digital humanities centers and institutes (probably at least one hundred worldwide, some of them estab\\xad lished for a decade or more with staffs numbering in the dozens): these are served by an organization known as centerNet. There have been digital humanities manifestos (I know of at least two) and FAQs, colloquia and symposia, workshops and special sessions. Not to mention, of course, that a gloss or explanation of digital humani\\xad ties is implicit in every mission statement, every call for papers and proposals, every What Is Digital Humanities and What’s It Doing in English Departments?Matthew G. Kirschenbaum ADE and the Association of Departments of En\\xadglish are trademarks owned by the Modern Language Association. © by the Association of Departments of En\\xadglish, CrossRef DOI: 10.1632/ade.150.55, ISSN 0001-0898',\n",
       " 'chunk_char_count': 845,\n",
       " 'chunk_word_count': 129,\n",
       " 'chunk_token_count': 211.25,\n",
       " 'embedding': array([ 2.03686710e-02,  3.22138183e-02, -2.67556552e-02,  4.90098028e-04,\n",
       "        -3.55669297e-02,  2.78598946e-02,  2.57898122e-02, -1.38313016e-02,\n",
       "        -1.12787951e-02, -3.82306017e-02,  1.95373986e-02, -1.39586646e-02,\n",
       "         3.32837701e-02, -3.31956930e-02,  5.57515724e-03, -7.72957411e-03,\n",
       "        -1.58331711e-02,  5.72767295e-02, -1.38711743e-02, -2.59399228e-02,\n",
       "         2.67086644e-02,  5.82799017e-02, -4.81107049e-02,  2.97391377e-02,\n",
       "        -2.62749847e-02, -2.70614848e-02, -4.99893799e-02,  5.14414348e-02,\n",
       "         4.90384065e-02,  2.81234756e-02, -1.02697015e-02, -1.63277052e-02,\n",
       "         3.19685712e-02,  2.07591299e-02,  1.77544882e-06, -1.15332194e-02,\n",
       "         2.83066626e-03, -2.78118160e-03,  2.94591184e-03, -3.41742858e-02,\n",
       "         1.15845136e-01,  1.02778012e-02, -3.67695615e-02, -4.17263582e-02,\n",
       "         1.49909100e-02,  4.43499908e-02,  7.97422677e-02, -5.20147681e-02,\n",
       "        -2.38955058e-02,  3.70393805e-02, -1.94947526e-04, -3.81180048e-02,\n",
       "         4.18222584e-02, -1.13094342e-03, -5.76943234e-02,  6.58450946e-02,\n",
       "        -1.27668949e-02,  7.30826482e-02,  7.86146671e-02,  1.73048861e-02,\n",
       "         2.71668052e-03,  4.22895029e-02,  4.90806717e-03, -3.22947949e-02,\n",
       "        -3.04779466e-02, -7.85789825e-03,  2.41719410e-02, -2.61173043e-02,\n",
       "         4.05355394e-02,  3.88675136e-03,  1.34138763e-01, -1.97801180e-02,\n",
       "         4.01884764e-02,  1.40380207e-02,  1.93927176e-02,  5.93617819e-02,\n",
       "        -4.37181480e-02,  3.67147215e-02, -2.37739459e-02, -2.61610057e-02,\n",
       "         4.97718621e-03, -4.56772186e-02,  3.44040617e-02,  9.17798579e-02,\n",
       "         6.20598756e-02,  1.37489277e-03,  1.64236929e-02,  2.41574589e-02,\n",
       "         2.08162498e-02, -1.54982032e-02,  4.61663455e-02,  5.73631935e-03,\n",
       "         2.11172383e-02,  3.13303471e-02,  1.84145458e-02,  1.56210260e-02,\n",
       "        -3.47397244e-03, -7.91187435e-02,  3.35081927e-02,  5.99679835e-02,\n",
       "        -1.11396341e-02, -2.18378492e-02, -2.94392393e-03,  4.61416459e-03,\n",
       "         8.23179334e-02,  5.15739620e-03, -6.55106306e-02,  7.90016651e-02,\n",
       "         3.43968049e-02,  4.74197604e-03, -3.96478139e-02, -2.31708456e-02,\n",
       "        -5.93773508e-03, -2.42589749e-02, -1.49772605e-02, -4.74400856e-02,\n",
       "         1.77627280e-02, -1.22765657e-02, -2.89424639e-02, -4.65844758e-03,\n",
       "        -1.10845128e-02,  2.84266714e-02, -4.19098958e-02, -1.87040158e-02,\n",
       "        -5.31739555e-03,  8.64505023e-02, -1.59297716e-02,  1.99637841e-02,\n",
       "        -2.39617676e-02,  5.48869045e-03,  3.56300697e-02,  1.01126041e-02,\n",
       "         2.51475032e-02, -7.99608529e-02, -9.49349720e-03, -3.75037752e-02,\n",
       "         3.57883386e-02,  1.07316533e-02,  1.62779540e-02, -3.30670960e-02,\n",
       "         4.95095737e-02, -2.96572186e-02,  4.39671539e-02,  2.70553399e-02,\n",
       "         4.68508853e-03, -2.00851355e-02,  2.29695793e-02, -4.37222645e-02,\n",
       "        -3.32137048e-02,  1.00229690e-02, -2.73983530e-03, -9.60049406e-03,\n",
       "        -3.18200141e-02, -8.92812200e-03,  1.01765178e-01, -4.32857871e-03,\n",
       "         2.56112758e-02,  5.17040957e-03,  1.16284266e-02, -2.05947068e-02,\n",
       "         3.33942994e-02,  4.89821211e-02, -3.43278907e-02,  4.16310430e-02,\n",
       "         2.47154804e-03, -3.09903380e-02,  1.85921334e-03, -1.04852468e-02,\n",
       "        -4.55084965e-02,  7.58509338e-02,  3.63674201e-02,  6.11073039e-02,\n",
       "        -1.54842921e-02,  4.63240693e-04,  1.00038201e-02,  5.09102196e-02,\n",
       "         6.20470420e-02,  3.62791982e-03,  1.41041148e-02,  3.01931463e-02,\n",
       "         2.58785021e-02, -3.32023501e-02, -1.20436018e-02,  2.43458357e-02,\n",
       "         7.44313374e-02,  1.52498167e-02, -9.01537761e-03, -1.06902828e-03,\n",
       "        -6.08419999e-03, -5.01533179e-03, -9.03935917e-03,  1.55289406e-02,\n",
       "         7.87215754e-02,  2.16973405e-02,  9.16068442e-03, -1.09749306e-02,\n",
       "         2.65040658e-02, -6.65995553e-02, -6.18023565e-04,  5.69740357e-03,\n",
       "         3.91419902e-02, -4.23858128e-02,  1.72417704e-02,  9.07719061e-02,\n",
       "         5.64169139e-02, -1.55881867e-02,  7.98795074e-02, -2.00209972e-02,\n",
       "         5.16396537e-02,  8.29018429e-02,  2.66815014e-02, -4.23311070e-02,\n",
       "        -1.02471821e-02,  2.01818813e-02,  3.69619355e-02, -5.84463291e-02,\n",
       "        -3.46860103e-02, -5.65329334e-03,  4.00951551e-03,  7.57600889e-02,\n",
       "        -1.93042904e-02,  2.00370718e-02, -3.49399112e-02, -6.09887857e-03,\n",
       "        -3.79789397e-02,  7.29106218e-02,  2.21387041e-03,  3.22148204e-02,\n",
       "        -2.00968515e-02,  1.07259333e-01, -4.25157472e-02,  5.84066752e-03,\n",
       "        -5.99165959e-03,  1.22206099e-02, -5.12814559e-02, -5.88829517e-02,\n",
       "         9.29280221e-02,  4.80169132e-02,  6.48945048e-02, -3.31055932e-02,\n",
       "         4.72780429e-02,  1.86108630e-02,  5.93367331e-02,  2.80744322e-02,\n",
       "         5.60166091e-02, -2.77539808e-02,  6.65192306e-02,  2.98657417e-02,\n",
       "        -2.31277663e-02,  2.77866144e-02, -3.66910850e-03, -2.02328693e-02,\n",
       "        -1.45852016e-02, -3.97568219e-04, -7.25944992e-03, -8.60271510e-03,\n",
       "         1.62073541e-02, -1.10781891e-02, -2.88948454e-02, -3.21511142e-02,\n",
       "        -4.28251456e-03, -2.77969968e-02,  5.89134358e-02,  3.15941051e-02,\n",
       "        -4.29975092e-02, -5.76992333e-02,  3.96752767e-02,  2.42283661e-02,\n",
       "        -2.89443675e-02, -1.53419916e-02, -7.07700988e-03,  6.85455801e-04,\n",
       "        -7.40058497e-02, -2.56929384e-03,  1.04922298e-02,  3.01563609e-02,\n",
       "        -3.43268714e-03, -1.39527386e-02, -4.09588125e-03,  4.06066934e-03,\n",
       "         4.02132384e-02,  3.86278071e-02,  3.57858674e-03, -2.21763998e-02,\n",
       "        -7.54063367e-04, -5.23944758e-03,  3.34755518e-02, -2.20412333e-02,\n",
       "        -1.45443610e-03,  2.91756913e-02, -2.48913392e-02, -6.63890392e-02,\n",
       "         2.00806595e-02, -1.69066824e-02,  2.63508130e-02, -1.28231877e-02,\n",
       "        -4.75506410e-02, -9.05252434e-03, -1.78130250e-02,  2.30546892e-02,\n",
       "        -2.58450001e-03, -3.39444205e-02,  9.04290006e-03,  3.68951783e-02,\n",
       "         1.02591580e-02,  5.09803966e-02,  4.24760394e-02, -1.10273191e-03,\n",
       "        -3.24503221e-02, -9.75006670e-02, -2.98275542e-03,  2.30142325e-02,\n",
       "         1.01062488e-02, -1.62222311e-02, -7.40114227e-03, -2.18496798e-03,\n",
       "        -5.21941623e-03, -7.76111111e-02, -2.18940955e-02,  1.93121657e-02,\n",
       "        -1.09399902e-02,  2.60489248e-02, -4.38448265e-02, -3.62649304e-03,\n",
       "         3.15969549e-02, -2.10613534e-02, -5.39064258e-02,  3.17450948e-02,\n",
       "         6.28245771e-02, -6.30827695e-02,  4.93287817e-02,  8.25503282e-03,\n",
       "        -1.69138853e-02, -3.46104354e-02, -4.64766752e-03,  2.81197987e-02,\n",
       "        -2.12736987e-02, -1.48426024e-02,  1.19550396e-02, -1.47937704e-02,\n",
       "        -1.73441216e-03,  8.53424072e-02,  7.18577020e-03,  7.55331740e-02,\n",
       "        -2.38262117e-02, -3.91612127e-02,  2.25474015e-02, -3.27544585e-02,\n",
       "         3.15844975e-02, -3.65787521e-02,  2.03357618e-02,  2.78688800e-02,\n",
       "        -8.99307244e-03,  1.61534210e-03,  1.22691141e-02,  3.40444185e-02,\n",
       "         2.80507598e-02,  6.05834797e-02, -1.16357217e-02,  3.26456428e-02,\n",
       "        -7.24615715e-03,  2.18211114e-02, -5.41593209e-02, -6.31543249e-02,\n",
       "         1.56894904e-02, -6.44616187e-02,  2.19765082e-02, -5.37688583e-02,\n",
       "        -4.45356183e-02,  2.25752126e-02, -1.43710431e-03, -2.33334117e-02,\n",
       "        -1.87359061e-02, -6.55864947e-04,  8.72617494e-03, -9.16710198e-02,\n",
       "        -3.14949378e-02, -3.37416343e-02, -3.90963033e-02, -2.21639825e-03,\n",
       "        -2.51971986e-02, -5.94791658e-02,  1.28603606e-02, -1.71022508e-02,\n",
       "        -8.91545787e-03, -3.76547314e-02, -2.66256966e-02, -2.72752568e-02,\n",
       "         1.14109023e-02, -2.33997982e-02, -2.75805723e-02,  5.22686616e-02,\n",
       "         3.24884765e-02,  1.69642903e-02, -1.32758508e-03,  2.01424267e-02,\n",
       "         3.58726308e-02, -5.68966158e-02,  6.28138101e-03, -2.25179386e-03,\n",
       "         2.80722696e-02, -3.81404236e-02, -2.57194843e-02, -5.07058203e-02,\n",
       "        -2.80868020e-02, -1.31126028e-02,  5.45060001e-02,  5.58439158e-02,\n",
       "        -3.67927775e-02, -1.49227176e-02, -3.52658778e-02,  3.61145735e-02,\n",
       "         1.74193121e-02,  6.55562943e-03,  1.22174388e-02, -2.61776745e-02,\n",
       "         4.08061221e-02, -4.09593135e-02,  7.72684440e-03, -4.75289579e-03,\n",
       "        -6.13308027e-02, -2.47754287e-02, -2.41730548e-03, -3.55808018e-03,\n",
       "         3.55652086e-02, -3.63926142e-02, -3.23656946e-02,  1.01536587e-02,\n",
       "         6.07542810e-04, -4.35475409e-02, -1.22106681e-03,  3.25817727e-02,\n",
       "         8.63281265e-03,  6.98810071e-02,  2.51162332e-02, -5.58330081e-02,\n",
       "        -3.51062021e-03,  2.35438365e-02, -7.66947865e-02, -1.06437579e-02,\n",
       "        -6.47998080e-02, -5.21630123e-02,  2.92165596e-02,  4.50498946e-02,\n",
       "        -2.41631586e-02,  3.99622619e-02, -1.34920757e-02, -1.15765348e-01,\n",
       "         5.95638435e-03, -7.18959793e-03,  3.97156477e-02,  2.53711529e-02,\n",
       "        -5.06108068e-02, -6.08341843e-02, -2.97008008e-02,  3.49616520e-02,\n",
       "        -3.95778902e-02, -7.21964687e-02, -8.28440767e-03, -2.21446319e-03,\n",
       "         3.49555840e-03, -2.40156101e-03,  3.52514838e-03,  6.82582846e-03,\n",
       "        -7.50500560e-02,  1.60729326e-02, -3.78169212e-03, -4.64192145e-02,\n",
       "        -3.42251658e-02, -3.04757729e-02, -2.45401748e-02, -3.14143859e-02,\n",
       "         1.46161148e-03, -1.65520180e-02, -4.24463116e-02, -7.83642230e-04,\n",
       "         3.17285545e-02, -1.20548010e-02,  2.62850765e-02, -1.64285842e-02,\n",
       "        -3.36125819e-03, -4.42214124e-02, -5.65988533e-02,  4.40816581e-02,\n",
       "         2.83231703e-03, -5.62560074e-02, -1.39685851e-02, -2.99807526e-02,\n",
       "         3.11297569e-02, -2.94648688e-02,  3.36354561e-02, -5.66772036e-02,\n",
       "        -5.97025221e-03,  1.46766281e-04,  4.91159819e-02, -3.31039689e-02,\n",
       "         8.37142486e-03,  1.32478196e-02,  2.09174287e-02,  6.93344101e-02,\n",
       "        -3.83568741e-02,  7.91944563e-03,  7.11593125e-03,  1.49920816e-02,\n",
       "        -3.16123590e-02,  5.69127612e-02,  6.02993788e-03,  4.28129248e-02,\n",
       "        -7.80222146e-03, -1.26459617e-02,  4.10182290e-02,  5.15632145e-03,\n",
       "         2.51086168e-02, -2.75683012e-02,  5.31688752e-03, -5.33971302e-02,\n",
       "         3.29418592e-02,  7.40959346e-02,  3.34474705e-02,  1.81689747e-02,\n",
       "        -3.09427604e-02,  2.95813512e-02,  8.37018061e-03, -1.97037534e-05,\n",
       "        -4.60494831e-02, -3.61242071e-02,  7.09398324e-03, -2.19147038e-02,\n",
       "         1.68088060e-02, -5.13767228e-02, -7.73548558e-02,  6.69614924e-03,\n",
       "         5.71290068e-02, -1.22040901e-02,  2.56397128e-02, -5.51080704e-02,\n",
       "        -2.90482119e-02,  2.93174107e-02,  2.12430172e-02,  1.55217582e-02,\n",
       "        -3.95146906e-02, -6.37634620e-02, -3.12799402e-02, -1.74235422e-02,\n",
       "        -4.91199642e-02, -7.82854781e-02,  4.53196699e-03, -2.34885067e-02,\n",
       "         4.00033500e-03, -2.74245180e-02, -3.29389386e-02,  5.35587780e-02,\n",
       "        -5.37642613e-02,  1.10487035e-02, -2.02718806e-02, -5.26984881e-33,\n",
       "        -4.76044283e-04, -5.63186705e-02,  2.85577681e-02, -1.05079018e-01,\n",
       "        -4.95856628e-02,  4.29043866e-04, -8.37241393e-03,  3.21457349e-02,\n",
       "        -3.19661684e-02,  6.93620220e-02, -5.45909740e-02,  5.66308107e-03,\n",
       "        -2.26342715e-02, -1.57209989e-02,  3.15498374e-03, -5.91531768e-03,\n",
       "         9.69008915e-03,  1.19800353e-02,  1.44957174e-02,  2.01728903e-02,\n",
       "         5.38479770e-03, -4.04844061e-02, -1.01193478e-02, -2.74273697e-02,\n",
       "         3.94137353e-02, -8.24922882e-03, -3.65904123e-02, -1.21254409e-02,\n",
       "         3.63377891e-02,  1.33829173e-02, -1.04494486e-02,  2.90920492e-02,\n",
       "        -1.95545014e-02, -3.92379984e-02,  1.48134222e-02,  4.60651405e-02,\n",
       "        -8.19652677e-02,  4.41948473e-02,  4.71391762e-03,  5.82638606e-02,\n",
       "         9.47202146e-02, -5.66494949e-02,  1.80082228e-02, -1.98752228e-02,\n",
       "        -2.76028384e-02,  8.45776778e-03,  1.96242500e-02,  1.93038434e-02,\n",
       "        -9.37160198e-03, -7.08200559e-02, -4.09940258e-02, -2.13135537e-02,\n",
       "        -3.62978354e-02,  1.30672799e-02,  2.44315341e-03, -6.43678010e-02,\n",
       "         1.66322570e-02,  2.38295086e-02, -8.38594437e-02,  1.33000454e-02,\n",
       "        -6.97640702e-02, -1.08067160e-02,  7.57111162e-02, -6.20705970e-02,\n",
       "        -1.04243038e-02,  1.82183422e-02, -3.42057906e-02,  2.64631826e-02,\n",
       "         1.89231895e-02,  4.53671776e-02,  1.98237412e-02, -3.84117439e-02,\n",
       "        -5.37357368e-02,  7.91767240e-02, -2.98071429e-02, -1.62476450e-02,\n",
       "         3.22213732e-02, -2.80380802e-04,  1.13075962e-02,  3.08526605e-02,\n",
       "        -2.49904487e-02, -1.47230942e-02, -2.14008633e-02, -8.37328564e-03,\n",
       "         5.95605783e-02, -4.44579236e-02,  2.77391318e-02, -5.19635081e-02,\n",
       "        -2.03656275e-02, -6.10180534e-02,  8.67214985e-03, -4.53221872e-02,\n",
       "        -2.86254827e-02, -7.61742219e-02, -1.03024291e-02,  3.98341976e-02,\n",
       "        -5.34700789e-02,  7.51690427e-03, -4.90470417e-03, -1.39113013e-02,\n",
       "         3.85033502e-03, -9.39421915e-03,  7.19005195e-03,  6.61870465e-02,\n",
       "         2.07363665e-02, -1.08340883e-03, -7.08568422e-03,  1.77883096e-02,\n",
       "         2.33699773e-02, -1.61645263e-02,  1.67962760e-02,  1.69023089e-02,\n",
       "         6.81902375e-03,  1.88610107e-02,  2.08183378e-02,  9.62257944e-03,\n",
       "         1.12752216e-02, -5.34339435e-03,  2.01152004e-02, -3.90118174e-03,\n",
       "         4.29680459e-02, -1.82687100e-02,  3.38909752e-03, -1.73130054e-02,\n",
       "        -2.77295168e-02,  6.12187898e-03, -3.18465233e-02, -2.33543050e-02,\n",
       "         5.09879701e-02, -5.58851436e-02, -8.52180924e-03, -4.66704369e-03,\n",
       "         2.58313577e-07,  1.87814776e-02, -1.83208864e-02,  3.13308500e-02,\n",
       "         2.03831475e-02,  8.00627097e-03, -2.46638898e-02,  3.44606973e-02,\n",
       "         1.84984487e-02, -3.02123819e-02, -1.73573289e-02,  3.47173028e-02,\n",
       "         1.68413352e-02,  9.78041813e-03,  8.42313189e-03, -5.31023741e-02,\n",
       "        -9.00462642e-02, -1.68477278e-02, -1.38757629e-02, -3.61217372e-02,\n",
       "         2.82503683e-02, -3.40965092e-02, -1.67917218e-02,  5.16915023e-02,\n",
       "        -3.18052098e-02, -6.25145957e-02,  3.36828046e-02, -5.08857258e-02,\n",
       "         5.30953221e-02,  4.87916060e-02, -1.70545261e-02, -5.86543940e-02,\n",
       "        -2.70579178e-02,  3.02013056e-03, -4.04371433e-02,  3.43166739e-02,\n",
       "         4.28038836e-03, -3.39370524e-03,  3.45627265e-03,  1.63512351e-03,\n",
       "        -3.50283571e-02, -1.58296023e-02, -1.62803903e-02,  3.16864997e-02,\n",
       "         4.50856350e-02,  4.01330180e-02,  3.00802179e-02,  3.05161253e-03,\n",
       "         3.68988141e-02, -2.24699136e-02, -1.60060711e-02,  1.29015446e-02,\n",
       "        -3.07142641e-02,  2.15100776e-02,  2.12536212e-02,  7.58596696e-03,\n",
       "        -1.72948446e-02,  4.07146588e-02, -6.05423748e-02,  4.83701266e-02,\n",
       "         9.24747344e-03,  2.97292545e-02, -4.39271033e-02,  1.90420244e-02,\n",
       "        -2.18668790e-03,  1.67551115e-02, -8.28126259e-03,  3.12706875e-03,\n",
       "         1.55308116e-34,  1.55259892e-02, -9.44919977e-03, -3.42769027e-02,\n",
       "         3.66604477e-02,  3.64191048e-02,  3.66765521e-02, -1.33702485e-02,\n",
       "        -3.81873176e-02,  2.01619565e-02,  1.86564475e-02, -1.40316775e-02])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the output by inputting a number from the indices\n",
    "pages_and_chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4dbf1e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape:  torch.Size([1500, 768])\n",
      "Time take to get scores on 1500 embeddings: 0.00132 seconds.\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(100 * embeddings.shape[0], 768).to(device)\n",
    "print(f\"Embeddings shape:  {larger_embeddings.shape}\")\n",
    "\n",
    "# Perform dot product across 168,000 embeddings\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "embeddings.dtype\n",
    "end_time = timer()\n",
    "\n",
    "print(\n",
    "    f\"Time take to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
